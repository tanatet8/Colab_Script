"""
Full Reasoning Prompt Generator (9 umbrellas / 45 subtypes) — v2 (offline)
----------------------------------------------------------------------------
- Offline 100% (no API). Deterministic with seed.
- Supports depth/difficulty, formalism scaffolds, distractors, redundancy check.
- Bilingual output (TH/EN) + ZH guard line.
- Saves Markdown with a Redundancy Check table appended.

Usage (Python):
    from full_reasoning_prompt_generator_45types_v2 import gen_batch
    md = gen_batch(start_num=1, n=5, reasoning_type="analogical", depth=2, seed=42,
                   save_path="prompts_1_5.md")
    print(md[:500])

CLI:
    python full_reasoning_prompt_generator_45types_v2.py --start 101 --n 8 --type causal --depth 3 --seed 2025 --save ./prompts.md

Author: Offline generator upgrade (v2)
"""

from __future__ import annotations

import argparse
import random
import textwrap
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional

# ------------------------------ Taxonomy (9 x 5 = 45) ------------------------------

TAXONOMY: Dict[str, List[str]] = {
    "analogical": [
        "structure_mapping", "surface_similarity", "cross_domain", "schema_induction", "relational_abstraction"
    ],
    "causal": [
        "common_cause", "intervention", "mediation", "confounding", "causal_dag_design"
    ],
    "probabilistic": [
        "bayesian_update", "base_rate", "conditional_independence", "expected_value", "uncertainty_quantification"
    ],
    "counterfactual": [
        "minimal_change", "necessary_sufficient", "regret_analysis", "path_dependency", "policy_counterfactual"
    ],
    "temporal": [
        "timeline_ordering", "scheduling_tradeoff", "temporal_consistency", "prediction_extrapolation", "interval_reasoning"
    ],
    "abductive": [
        "best_explanation", "hypothesis_pruning", "anomaly_explanation", "evidence_weighing", "abductive_plausibility"
    ],
    "meta_reasoning": [
        "plan_selection", "self_evaluation", "error_analysis", "decomposition", "reflective_replanning"
    ],
    "autonomous_cognitive_system": [
        "goal_setting", "tool_selection", "feedback_integration", "safety_constraints", "resource_budgeting"
    ],
    "emergent_intelligence": [
        "pattern_discovery", "rule_induction", "analogy_cluster", "coordination", "compositionality"
    ]
}

# ------------------------------ Pools (seed lists; expand in your project) ------------------------------

DOMAIN_CONTEXTS = [
    "โลจิสติกส์อีคอมเมิร์ซ", "การแพทย์คลินิก", "การศึกษา STEM", "ห่วงโซ่อุปทานอาหาร", "นโยบายสาธารณะ",
    "ฟินเทคและการให้สินเชื่อ", "พลังงานหมุนเวียน", "เกมกลยุทธ์แบบหลายผู้เล่น", "หุ่นยนต์ในคลังสินค้า",
    "ระบบขนส่งมวลชน", "ความปลอดภัยไซเบอร์", "การท่องเที่ยวเชิงอนุรักษ์", "การเกษตรแม่นยำ", "กีฬาและโภชนาการ"
]

TASKS = [
    "วิเคราะห์", "อธิบาย", "ออกแบบขั้นตอน", "เปรียบเทียบ", "จัดลำดับเหตุผล",
    "ตัดสินใจ", "โต้แย้งและป้องกันข้อโต้แย้ง", "วางแผน", "ตรวจความสอดคล้อง"
]

CONSTRAINTS = [
    "อธิบายทีละขั้น", "ใช้เหตุผล 3–5 ฮอป", "อ้างอิงหลักฐาน/ตัวแปร", "ห้ามสรุปแบบกำปั้นทุบดิน",
    "ให้ตัวตรวจ sanity check", "ให้ตัวแปรนิยามชัด", "เปรียบเทียบทางเลือกอย่างยุติธรรม",
    "ระบุสมมติฐานอย่างชัดเจน", "ระบุความไม่แน่นอน"
]

DISTRACTORS = [
    "ข้อมูลตัวอย่างที่ไม่เป็นตัวแทน",
    "ตัวเลขที่ชวนให้ละเลย base-rate",
    "สหสัมพันธ์ที่ดูเหมือนเป็นเหตุเป็นผล",
    "กรณีขอบที่ขัดแย้งกับกรณีทั่วไป",
    "ข้อยกเว้นที่ทำให้สับสนกับกฎ",
]

# Fallacy pools (by umbrella, simplified)
FALLACIES = {
    "analogical": ["faulty_analogy", "surface_bias", "category_error"],
    "causal": ["post_hoc", "confounding", "correlation_vs_causation"],
    "probabilistic": ["base_rate_neglect", "conjunction_fallacy", "miscalibrated_uncertainty"],
    "counterfactual": ["wrong_world_change", "hindsight_bias", "overfitting_scenarios"],
    "temporal": ["planning_fallacy", "recency_bias", "telescoping_effect"],
    "abductive": ["cherry_picking", "insufficient_evidence", "overlooking_alternatives"],
    "meta_reasoning": ["premature_commitment", "confirmation_bias", "stopping_too_early"],
    "autonomous_cognitive_system": ["specification_gaming", "unsafe_shortcuts", "resource_overcommitment"],
    "emergent_intelligence": ["pattern_apophenia", "spurious_rules", "overgeneralization"]
}

# Entities pool per higher-level domain (tiny seed; expand later)
ENTITIES = {
    "โลจิสติกส์อีคอมเมิร์ซ": ["คำสั่งซื้อ", "โกดัง A", "ศูนย์คัดแยก", "รถขนส่ง", "ลูกค้า"],
    "การแพทย์คลินิก": ["ผู้ป่วย", "ยาต้นแบบ", "ยาหลอก", "อาการ", "การติดตามผล"],
    "การศึกษา STEM": ["ผู้เรียน", "ชุดแบบฝึก", "ครู", "การประเมิน", "กิจกรรมกลุ่ม"],
    "ฟินเทคและการให้สินเชื่อ": ["ผู้กู้", "คะแนนเครดิต", "อัตราดอกเบี้ย", "รายได้", "ประวัติชำระ"],
    "พลังงานหมุนเวียน": ["กังหันลม", "แผงโซลาร์", "โหลด", "แบตเตอรี่", "กริด"],
}

# ------------------------------ Depth presets ------------------------------

DEPTH_PRESETS = {
    1: dict(hops=2, constraints=1, distractors=1, formalism="none"),
    2: dict(hops=3, constraints=2, distractors=2, formalism="auto"),  # choose per umbrella
    3: dict(hops=4, constraints=3, distractors=3, formalism="auto"),  # and add extra scaffold
}

# Map umbrella -> default formalism for auto
AUTO_FORMALISM = {
    "analogical": "structure_map",
    "causal": "causal_graph",
    "probabilistic": "bayes_table",
    "counterfactual": "counterfactual_worlds",
    "temporal": "timeline",
    "abductive": "evidence_matrix",
    "meta_reasoning": "rubric_checklist",
    "autonomous_cognitive_system": "policy_loop",
    "emergent_intelligence": "pattern_grid",
}

# ------------------------------ Data classes ------------------------------

@dataclass
class PromptRow:
    prompt: str
    domain_context: str
    sub_type: str
    fallacy: str

# ------------------------------ Helpers ------------------------------

def rng_choice(rng: random.Random, seq: List[str]) -> str:
    return seq[rng.randrange(len(seq))]

def pick_entities_for_domain(domain: str, rng: random.Random, k: int = 4) -> List[str]:
    pool = ENTITIES.get(domain, [])
    if not pool:
        # generic entities
        pool = ["ตัวแปร A", "ตัวแปร B", "ตัวแปร C", "ตัวแปร D", "ตัวแปร E"]
    k = min(k, len(pool))
    return rng.sample(pool, k)

def choose_formalism(reasoning_type: str, depth: int, forced: Optional[str]) -> str:
    if forced and forced != "auto":
        return forced
    preset = DEPTH_PRESETS.get(depth, DEPTH_PRESETS[2])
    if preset["formalism"] not in (None, "auto", "none"):
        return preset["formalism"]
    if preset["formalism"] == "none":
        return "none"
    return AUTO_FORMALISM.get(reasoning_type, "none")

def build_scaffold(reasoning_type: str, formalism: str, entities: List[str], rng: random.Random, hops: int) -> str:
    """Return a scaffold string to include in the prompt. Purely offline."""
    if formalism == "none":
        return ""
    if formalism == "causal_graph":
        # simple ASCII DAG scaffold
        nodes = entities[:max(3, min(5, len(entities)))]
        edges = []
        for _ in range(hops):
            a, b = rng.sample(nodes, 2)
            edges.append(f"{a} -> {b}")
        conf = rng.choice(nodes)
        return textwrap.dedent(f"""
        [Scaffold: Causal DAG]
        Nodes: {", ".join(nodes)}
        Edges (candidate): {", ".join(edges)}
        Identify/Control Confounder(s): e.g., {conf}
        """).strip()
    if formalism == "bayes_table":
        # small Bayes table headers
        hyp = "H"  # hypothesis
        ev = "E"   # evidence
        # deterministic but pseudo
        prior_num = rng.randint(10, 60)
        prior = f"{prior_num}%"
        like_h = f"{rng.randint(50, 95)}%"
        like_not = f"{rng.randint(5, 50)}%"
        return textwrap.dedent(f"""
        [Scaffold: Bayesian Update]
        Hypothesis: {hyp} ; Evidence: {ev}
        Prior P({hyp}) = {prior}
        Likelihoods: P({ev}|{hyp}) = {like_h} ; P({ev}|¬{hyp}) = {like_not}
        Task: compute Posterior P({hyp}|{ev}) and explain in steps.
        """).strip()
    if formalism == "counterfactual_worlds":
        return textwrap.dedent(f"""
        [Scaffold: Counterfactual Worlds]
        World A (factual): list key conditions on entities: {", ".join(entities[:4])}
        World B (counterfactual): change exactly ONE minimal cause; keep others fixed.
        Compare outcomes and justify minimal-change principle.
        """).strip()
    if formalism == "timeline":
        e = entities[:4]
        return textwrap.dedent(f"""
        [Scaffold: Timeline / Partial Order]
        Events: {", ".join(e)}
        Constraints: {e[0]} before {e[1]} ; {e[2]} overlaps {e[3]} ; avoid contradictions.
        Provide a feasible ordering and justify.
        """).strip()
    if formalism == "structure_map":
        return textwrap.dedent(f"""
        [Scaffold: Structure-Mapping]
        Source system: define roles for {", ".join(entities[:3])}
        Target system: map correspondences and highlight relational invariants.
        """).strip()
    if formalism == "evidence_matrix":
        return textwrap.dedent(f"""
        [Scaffold: Evidence Matrix]
        List hypotheses H1..Hk and evidence items e1..em.
        Rate support/contradiction (-2..+2) and pick Best Explanation with trade-offs.
        """).strip()
    if formalism == "rubric_checklist":
        return textwrap.dedent(f"""
        [Scaffold: Meta-Reasoning Rubric]
        Plan → Execute → Check → Revise loop.
        Add failure tests and stopping criteria.
        """).strip()
    if formalism == "policy_loop":
        return textwrap.dedent(f"""
        [Scaffold: Policy Loop]
        Goal → Tool choice → Action → Feedback → Adjustment (iterate).
        Track resource and safety constraints.
        """).strip()
    if formalism == "pattern_grid":
        return textwrap.dedent(f"""
        [Scaffold: Pattern Grid]
        Observe recurring structures; propose candidate rules; test against counterexamples.
        """).strip()
    return ""

def select_subtype(reasoning_type: str, rng: random.Random) -> str:
    subs = TAXONOMY.get(reasoning_type, [])
    if not subs:
        return reasoning_type
    return rng_choice(rng, subs)

def build_constraints(rng: random.Random, k: int) -> List[str]:
    return rng.sample(CONSTRAINTS, k=min(k, len(CONSTRAINTS)))

def build_distractors(rng: random.Random, k: int) -> List[str]:
    return rng.sample(DISTRACTORS, k=min(k, len(DISTRACTORS)))

def fallacy_for(reasoning_type: str, rng: random.Random) -> str:
    pool = FALLACIES.get(reasoning_type, ["generic_bias"])
    return rng_choice(rng, pool)

def rules_ok(reasoning_type: str, sub_type: str, formalism: str, picks: Dict[str, str], depth: int) -> bool:
    """Simple sanity rules. Expand as needed."""
    # Example: probabilistic prompts at depth>=2 must include a bayes_table
    if reasoning_type == "probabilistic" and depth >= 2:
        if formalism != "bayes_table":
            return False
    if reasoning_type == "causal" and sub_type in ("confounding", "causal_dag_design"):
        if formalism != "causal_graph":
            return False
    if reasoning_type == "counterfactual" and depth >= 2:
        if formalism != "counterfactual_worlds":
            return False
    # Ensure constraints mention explanation for depth>=2
    if depth >= 2 and not any(("อธิบาย" in c or "explain" in c.lower()) for c in CONSTRAINTS):
        return False
    return True

# Umbrella-level bilingual template (we keep per-umbrella to reduce size)
UMBRELLA_TEMPLATES: Dict[str, List[str]] = {
    "analogical": [
        ("TH: ในบริบท {domain} ให้ทำ {task} สำหรับหัวข้อย่อย {sub_type} "
         "ด้วยการใช้อุปมาอุปไมยเชิงโครงสร้าง และอธิบายการแม็ปแบบทีละขั้น ({hops}-ฮอป). "
         "ให้ระบุข้อควรระวัง: หลีกเลี่ยง {fallacy}.\n"
         "EN: In {domain}, perform {task} for sub-type {sub_type} using structure-mapping. "
         "Explain correspondences in {hops} hops. Beware of {fallacy}.\n"
         "ZH-guard: 保持结构映射与逐步说明，避免表面相似误导。\n"),
    ],
    "causal": [
        ("TH: ในบริบท {domain} ให้ทำ {task} เรื่อง {sub_type} โดยเน้นเหตุและผล "
         "ออกแบบขั้นตอนระบุ/ควบคุมปัจจัยกวน และให้เหตุผลแบบทีละขั้น ({hops}-ฮอป). "
         "เตือนความผิดพลาดที่พบบ่อย: {fallacy}.\n"
         "EN: In {domain}, do {task} on {sub_type} with causal reasoning. "
         "Design a method to identify/control confounders; explain in {hops} hops. "
         "Common pitfall: {fallacy}.\n"
         "ZH-guard: 突出因果与混杂因素控制，逐步推理。\n"),
    ],
    "probabilistic": [
        ("TH: ในบริบท {domain} ให้ {task} ประเด็น {sub_type} โดยใช้กรอบความน่าจะเป็น "
         "และอธิบายการอัปเดตแบบเบย์ใน {hops} ขั้น. หลีกเลี่ยงความผิดพลาด: {fallacy}.\n"
         "EN: In {domain}, {task} the topic {sub_type} using probabilistic framing. "
         "Explain Bayesian-style updating in {hops} steps. Avoid {fallacy}.\n"
         "ZH-guard: 使用概率框架并逐步说明，不要忽视基率。\n"),
    ],
    "counterfactual": [
        ("TH: ในบริบท {domain} จงวิเคราะห์ {sub_type} แบบ counterfactual โดยเปรียบเทียบ World A/B "
         "และยึดหลัก minimal change อธิบาย {hops} ฮอป.\n"
         "EN: In {domain}, analyze {sub_type} counterfactually by contrasting World A/B "
         "with a minimal-change principle. Use {hops} hops.\n"
         "ZH-guard: 明确世界对照并保持最小变更。\n"),
    ],
    "temporal": [
        ("TH: ในบริบท {domain} จัดทำ {task} ที่เน้นลำดับเวลา/ความสอดคล้องของเหตุการณ์ ({sub_type}). "
         "ระบุข้อจำกัดและอธิบาย {hops} ฮอป.\n"
         "EN: In {domain}, perform {task} focusing on temporal ordering/consistency ({sub_type}). "
         "Explain in {hops} hops with constraints.\n"
         "ZH-guard: 明确时间顺序与一致性。\n"),
    ],
    "abductive": [
        ("TH: ในบริบท {domain} ให้ทำ {task} เพื่อค้นหา Best Explanation ({sub_type}) "
         "โดยชั่งน้ำหนักหลักฐาน อธิบาย {hops} ฮอป.\n"
         "EN: In {domain}, {task} to find the Best Explanation ({sub_type}) "
         "by weighing evidence. Explain in {hops} hops.\n"
         "ZH-guard: 列出候选解释并权衡证据。\n"),
    ],
    "meta_reasoning": [
        ("TH: ในบริบท {domain} ให้ทำ {task} เชิงเมตา ({sub_type}) "
         "โดยระบุแผน-ตรวจ-ปรับ แบบวนลูป และอธิบาย {hops} ฮอป.\n"
         "EN: In {domain}, perform meta-level {task} ({sub_type}) with a plan-check-revise loop. "
         "Explain in {hops} hops.\n"
         "ZH-guard: 规划→执行→检查→修正。\n"),
    ],
    "autonomous_cognitive_system": [
        ("TH: ในบริบท {domain} ให้ {task} สำหรับระบบกึ่งอัตโนมัติ ({sub_type}) "
         "เน้นข้อกำหนดด้านความปลอดภัย/ทรัพยากร และอธิบาย {hops} ฮอป.\n"
         "EN: In {domain}, {task} for an autonomous-style system ({sub_type}), "
         "highlight safety/resource constraints; explain in {hops} hops.\n"
         "ZH-guard: 关注安全与资源预算。\n"),
    ],
    "emergent_intelligence": [
        ("TH: ในบริบท {domain} ให้ {task} ด้านรูปแบบเกิดใหม่ ({sub_type}) ด้วยการค้นหา pattern/กฎ "
         "และตรวจข้อยกเว้น อธิบาย {hops} ฮอป.\n"
         "EN: In {domain}, {task} on emergent patterns ({sub_type}) by proposing patterns/rules "
         "and testing counterexamples. Explain in {hops} hops.\n"
         "ZH-guard: 发现模式并检验反例。\n"),
    ],
}

def render_prompt_block(reasoning_type: str, sub_type: str, domain: str, task: str,
                        constraints: List[str], distractors: List[str],
                        scaffold: str, fallacy: str, hops: int) -> str:
    template = rng_choice(random.Random(0), UMBRELLA_TEMPLATES.get(reasoning_type, [""]))
    header = f"# {reasoning_type.upper()} / {sub_type} — {domain}\n"
    body = template.format(domain=domain, sub_type=sub_type, task=task, hops=hops, fallacy=fallacy)
    given = "- Entities: " + ", ".join(pick_entities_for_domain(domain, random.Random(0), 4))
    cons = "\n".join([f"- {c}" for c in constraints])
    dist = "\n".join([f"- {d}" for d in distractors])
    scaffold_block = f"\n{scaffold}\n" if scaffold else ""
    block = textwrap.dedent(f"""
    {header}
    {body}
    **Given / Setup**
    {given}

    **Task**
    - {task} ให้เสร็จสมบูรณ์โดยยึดตามกรอบ {reasoning_type} / sub-type {sub_type}.

    **Constraints**
    {cons}

    **Distractors (intentional)**
    {dist}

    **Scaffold**
    {scaffold_block}
    **Deliverable**
    - อธิบายเหตุผลแบบทีละขั้น ({hops} ฮอป) พร้อม sanity checks
    - ระบุวิธีหลีกเลี่ยง fallacy: {fallacy}
    """).strip()
    return block

def sample_prompt(reasoning_type: str, sub_type: str, rng: random.Random,
                  depth: int, formalism: Optional[str]) -> Optional[PromptRow]:
    domain = rng_choice(rng, DOMAIN_CONTEXTS)
    task = rng_choice(rng, TASKS)
    fall = fallacy_for(reasoning_type, rng)
    ent = pick_entities_for_domain(domain, rng, 4)

    preset = DEPTH_PRESETS.get(depth, DEPTH_PRESETS[2])
    hops = preset["hops"]
    constraints = build_constraints(rng, preset["constraints"])
    distractors = build_distractors(rng, preset["distractors"])
    fm = choose_formalism(reasoning_type, depth, formalism)
    scaffold = build_scaffold(reasoning_type, fm, ent, rng, hops)

    picks = {"domain": domain, "task": task, "fallacy": fall, "formalism": fm}
    if not rules_ok(reasoning_type, sub_type, fm, picks, depth):
        return None

    text = render_prompt_block(reasoning_type, sub_type, domain, task, constraints, distractors, scaffold, fall, hops)
    return PromptRow(prompt=text, domain_context=domain, sub_type=sub_type, fallacy=fall)

def gen_batch(start_num: int = 1,
              n: int = 5,
              reasoning_type: str = "analogical",
              seed: int = 42,
              depth: int = 2,
              formalism: Optional[str] = None,
              save_path: Optional[str] = None,
              ensure_unique: bool = True) -> str:
    """
    Generate a batch of prompts (Markdown) with redundancy table.

    Args:
        start_num: starting index number for prompts
        n: number of prompts
        reasoning_type: one of TAXONOMY keys OR "mixed" to mix umbrellas
        seed: random seed (deterministic generation)
        depth: 1..3 using DEPTH_PRESETS
        formalism: override formalism ("auto"|"none"|"causal_graph"|...), or None to follow preset
        save_path: optional path to save .md
        ensure_unique: avoid duplicate (domain,sub_type,fallacy) triples

    Returns:
        Markdown string with prompts and a Redundancy Check table.
    """
    rng = random.Random(seed)
    rows: List[PromptRow] = []
    seen = set()
    md: List[str] = []

    umbrellas = list(TAXONOMY.keys())

    for i in range(n):
        # Reasoning type selection
        rt = reasoning_type
        if reasoning_type == "mixed":
            rt = rng_choice(rng, umbrellas)
        sub = select_subtype(rt, rng)

        # Try a few times to satisfy rules & uniqueness
        row: Optional[PromptRow] = None
        for _ in range(60):
            row = sample_prompt(rt, sub, rng, depth, formalism)
            if not row:
                continue
            key = (row.domain_context, row.sub_type, row.fallacy)
            if ensure_unique and key in seen:
                row = None
                continue
            seen.add(key)
            break

        if row is None:
            # fallback minimalist row
            row = PromptRow(
                prompt=f"# {rt.upper()} / {sub}\nTH: สร้างโจทย์ไม่สำเร็จ ลองสุ่มใหม่.\nEN: Generation failed; try again.",
                domain_context="unknown",
                sub_type=sub,
                fallacy="n/a"
            )
        rows.append(row)
        md.append(f"### Prompt {start_num + i}\n\n```md\n{row.prompt}\n```\n")

    # Redundancy Check table
    md.append("\n## Redundancy Check\n")
    md.append("| Prompt | domain_context | sub_type | fallacy |\n|---:|---|---|---|\n")
    for j, r in enumerate(rows, start=start_num):
        md.append(f"| {j} | {r.domain_context} | {r.sub_type} | {r.fallacy} |\n")

    out = "".join(md)
    if save_path:
        with open(save_path, "w", encoding="utf-8") as f:
            f.write(out)
    return out

def main():
    p = argparse.ArgumentParser(description="Offline Reasoning Prompt Generator v2")
    p.add_argument("--start", type=int, default=1)
    p.add_argument("--n", type=int, default=5)
    p.add_argument("--type", type=str, default="analogical", help='umbrella type or "mixed"')
    p.add_argument("--seed", type=int, default=42)
    p.add_argument("--depth", type=int, default=2, choices=[1,2,3])
    p.add_argument("--formalism", type=str, default=None, help='override formalism (e.g., "causal_graph", "bayes_table", "auto", "none")')
    p.add_argument("--save", type=str, default=None)
    args = p.parse_args()

    md = gen_batch(start_num=args.start, n=args.n, reasoning_type=args.type,
                   seed=args.seed, depth=args.depth, formalism=args.formalism,
                   save_path=args.save)
    print(md[:1000] + ("\n...\n" if len(md) > 1000 else ""))

if __name__ == "__main__":
    main()
