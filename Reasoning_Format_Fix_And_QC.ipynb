{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanatet8/Colab_Script/blob/main/Reasoning_Format_Fix_And_QC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 0) MOUNT GOOGLE DRIVE & GLOBAL SETTINGS\n",
        "# ============================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ‚úèÔ∏è ‡∏ï‡∏±‡πâ‡∏á‡∏û‡∏≤‡∏ò‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
        "SRC = '/content/drive/MyDrive/Dataset_Curation/causal_batch_01.md'\n",
        "DST_KEEP_NUM   = SRC.replace('.md', '_FIXED_KEEPNUM.md')\n",
        "DST_RENUMBERED = SRC.replace('.md', '_FIXED_RENUMBERED.md')\n",
        "\n",
        "# Batch id ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ\n",
        "BATCH_ID_EXPECT = 'causal_batch_01'\n",
        "\n",
        "# reasoning_type ‚Üí tier (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô 1..6)\n",
        "TIER_MAPPING = {\n",
        "    # Tier 1: Symbolic & Deterministic\n",
        "    'symbolic_reasoning': 1, 'deductive_reasoning': 1, 'deductive': 1,\n",
        "    'if_then_only_if_iff': 1, 'contrapositive_xor': 1,\n",
        "    'contradiction_trap': 1, 'logic_trap': 1, 'fallacy_detection': 1,\n",
        "    'symbolic_recursion': 1, 'logic_tree': 1, 'belief_modeling': 1,\n",
        "\n",
        "    # Tier 2: Causal & Counterfactual & commonsense-ish\n",
        "    'causal_reasoning': 2, 'causal': 2, 'counterfactual_reasoning': 2,\n",
        "    'emotional_behavioral_cause': 2, 'daily_life_reasoning': 2,\n",
        "    'temporal_reasoning': 2, 'spatial_reasoning': 2,\n",
        "    'probabilistic_reasoning': 2, 'commonsense_reasoning': 2,\n",
        "\n",
        "    # Tier 3: Meta & Ambiguity\n",
        "    'meta_reasoning': 3, 'ambiguity_detection': 3,\n",
        "    'ambiguity_resolution': 3, 'weak_evidence_uncertainty': 3,\n",
        "    'language_driven_inference': 3, 'structural_analogy': 3,\n",
        "    'multi_hop_justification': 3,\n",
        "\n",
        "    # Tier 4: Belief Dynamics & Epistemology\n",
        "    'belief_revision': 4, 'epistemic_reasoning': 4,\n",
        "    'self_consistency_logic': 4, 'ontological_shift': 4,\n",
        "\n",
        "    # Tier 5: Multi-Agent & Recursive\n",
        "    'multi_agent_simulation': 5, 'perspective_reasoning': 5,\n",
        "    'recursive_inference': 5, 'perspective_clash': 5,\n",
        "\n",
        "    # Tier 6: Moral / Identity / Narrative / Advanced\n",
        "    'moral_ambiguity_tradeoff': 6, 'identity_loop_reasoning': 6,\n",
        "    'ethical_dilemma_decomposition': 6, 'planning_goal_based_reasoning': 6,\n",
        "    'deontic_reasoning': 6, 'narrative_causal_reasoning': 6,\n",
        "    'philosophical_logic': 6, 'analogical_reasoning': 6,\n",
        "    'heuristic_reasoning': 6, 'multi_lingual_reasoning': 6,\n",
        "\n",
        "    # Aliases ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏™‡∏∞‡∏Å‡∏î‡∏ï‡πà‡∏≤‡∏á\n",
        "    'commonsense': 2, 'probabilistic': 2, 'meta': 3, 'analogical': 6,\n",
        "}\n",
        "\n",
        "print(\"üéØ Ready\")\n",
        "print(\"SRC:\", SRC)\n",
        "print(\"DST_KEEP_NUM:\", DST_KEEP_NUM)\n",
        "print(\"Expected batch_id:\", BATCH_ID_EXPECT)"
      ],
      "metadata": {
        "id": "6Y7XUlj--xhg",
        "outputId": "0b4370c2-c39d-496e-b5f5-c700fe08a8b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "üéØ Ready\n",
            "SRC: /content/drive/MyDrive/Dataset_Curation/causal_batch_01.md\n",
            "DST_KEEP_NUM: /content/drive/MyDrive/Dataset_Curation/causal_batch_01_FIXED_KEEPNUM.md\n",
            "Expected batch_id: causal_batch_01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 1) LOAD FILE & SPLIT INTO BLOCKS\n",
        "# ============================================\n",
        "\n",
        "import re\n",
        "\n",
        "with open(SRC, 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# ‡∏à‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÅ‡∏ö‡∏ö \"## Prompt <‡πÄ‡∏•‡∏Ç>\" ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
        "parts = re.split(r'(##\\s*Prompt\\s+\\d+[^\\n]*\\n)', text)\n",
        "blocks = []\n",
        "for i in range(1, len(parts), 2):\n",
        "    header = parts[i].rstrip('\\n')\n",
        "    body   = parts[i+1] if i+1 < len(parts) else ''\n",
        "    blocks.append((header, body))\n",
        "\n",
        "print(f\"‡∏û‡∏ö {len(blocks)} blocks\")\n",
        "if blocks:\n",
        "    print(\"‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á header ‡πÅ‡∏£‡∏Å:\", blocks[0][0])"
      ],
      "metadata": {
        "id": "ktyBL0xQ-0xo",
        "outputId": "da00c632-ec9f-4fec-9c84-264e958075fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‡∏û‡∏ö 100 blocks\n",
            "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á header ‡πÅ‡∏£‡∏Å: ## Prompt 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 2) DEFINE FIX FUNCTION\n",
        "# ============================================\n",
        "\n",
        "MODEL_SIZE_TOKEN = re.compile(r'^\\s*(\\d+)\\s*[Bb]\\s*$', re.I)\n",
        "INT_TOKEN        = re.compile(r'^\\s*(\\d+)\\s*$')\n",
        "\n",
        "def _infer_tier_from_reasoning_type(text: str) -> str:\n",
        "    \"\"\"‡∏´‡∏≤ tier ‡∏à‡∏≤‡∏Å reasoning_type ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡πÉ‡∏ô mapping\"\"\"\n",
        "    m = re.search(r'(?m)^\\s*reasoning_type\\s*:\\s*([^\\s]+)', text)\n",
        "    if m:\n",
        "        key = m.group(1).strip().lower()\n",
        "        if key in TIER_MAPPING:\n",
        "            return str(TIER_MAPPING[key])\n",
        "    return '2'  # fallback ‡∏Å‡∏•‡∏≤‡∏á ‡πÜ\n",
        "\n",
        "def fix_block(body: str) -> str:\n",
        "    \"\"\"\n",
        "    ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ block:\n",
        "    1. ‡πÉ‡∏™‡πà Metadata ‡∏´‡∏±‡∏ß‡πÅ‡∏£‡∏Å‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
        "    2. batch_id ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n",
        "    3. tier/model_size ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ï‡πâ Metadata ‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
        "    4. ‡∏•‡∏ö Metadata ‡∏ã‡πâ‡∏≥ ‡πÅ‡∏•‡∏∞ tier/model_size ‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏≠‡∏¢‡∏π‡πà\n",
        "    5. --- ‡∏≠‡∏¢‡∏π‡πà‡∏ó‡πâ‡∏≤‡∏¢ block ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
        "    \"\"\"\n",
        "\n",
        "    # === Step 1: ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ñ‡πà‡∏≤ tier/model_size ‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πà‡∏Å‡πà‡∏≠‡∏ô ===\n",
        "    raw_tier = None\n",
        "    raw_model_size = None\n",
        "\n",
        "    # ‡∏´‡∏≤ tier ‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏ö‡∏•‡πá‡∏≠‡∏Å\n",
        "    tier_matches = re.findall(r'(?m)^\\s*tier\\s*:\\s*([^\\n]+)$', body)\n",
        "    if tier_matches:\n",
        "        raw_tier = tier_matches[0].strip()  # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠\n",
        "\n",
        "    # ‡∏´‡∏≤ model_size ‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏ö‡∏•‡πá‡∏≠‡∏Å\n",
        "    ms_matches = re.findall(r'(?m)^\\s*model_size\\s*:\\s*([^\\n]+)$', body)\n",
        "    if ms_matches:\n",
        "        raw_model_size = ms_matches[0].strip()\n",
        "\n",
        "    # === Step 2: Normalize tier ‡πÅ‡∏•‡∏∞ model_size ===\n",
        "    model_size = raw_model_size\n",
        "    tier_val = None\n",
        "\n",
        "    if raw_tier:\n",
        "        if MODEL_SIZE_TOKEN.match(raw_tier):  # ‡πÄ‡∏ä‡πà‡∏ô 13B, 30B\n",
        "            model_size = MODEL_SIZE_TOKEN.match(raw_tier).group(1) + 'B'\n",
        "        else:\n",
        "            mi = INT_TOKEN.match(raw_tier)\n",
        "            if mi:\n",
        "                n = int(mi.group(1))\n",
        "                if n > 6:\n",
        "                    model_size = f\"{n}B\"\n",
        "                else:\n",
        "                    tier_val = str(n)\n",
        "            else:\n",
        "                # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÄ‡∏•‡∏Ç‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
        "                md = re.search(r'(\\d+)', raw_tier)\n",
        "                if md:\n",
        "                    n = int(md.group(1))\n",
        "                    if n > 6:\n",
        "                        model_size = f\"{n}B\"\n",
        "                    else:\n",
        "                        tier_val = str(n)\n",
        "\n",
        "    # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ tier ‡πÉ‡∏´‡πâ infer ‡∏à‡∏≤‡∏Å reasoning_type\n",
        "    if tier_val is None:\n",
        "        tier_val = _infer_tier_from_reasoning_type(body)\n",
        "\n",
        "    # === Step 3: ‡∏•‡∏ö tier/model_size ‡πÅ‡∏•‡∏∞ Metadata ‡∏ã‡πâ‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡πà‡∏≠‡∏ô ===\n",
        "    # ‡∏•‡∏ö‡∏ó‡∏∏‡∏Å tier ‡πÅ‡∏•‡∏∞ model_size\n",
        "    body = re.sub(r'(?m)^\\s*tier\\s*:\\s*[^\\n]*\\n?', '', body)\n",
        "    body = re.sub(r'(?m)^\\s*model_size\\s*:\\s*[^\\n]*\\n?', '', body)\n",
        "\n",
        "    # === Step 4: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Metadata ===\n",
        "    # ‡∏´‡∏≤ Metadata ‡πÅ‡∏£‡∏Å‡∏™‡∏∏‡∏î\n",
        "    first_meta_match = re.search(r'(?m)^###\\s*Metadata\\s*$', body)\n",
        "\n",
        "    if first_meta_match:\n",
        "        # ‡∏°‡∏µ Metadata ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß\n",
        "        meta_start = first_meta_match.start()\n",
        "        meta_header_end = first_meta_match.end()\n",
        "\n",
        "        # ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á Metadata section (‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ñ‡∏±‡∏î‡πÑ‡∏õ)\n",
        "        rest_text = body[meta_header_end:]\n",
        "        next_section = re.search(\n",
        "            r'(?m)^(##\\s+Prompt|###\\s+(?!Metadata)|## Prompt \\()',\n",
        "            rest_text\n",
        "        )\n",
        "\n",
        "        if next_section:\n",
        "            meta_content_end = meta_header_end + next_section.start()\n",
        "        else:\n",
        "            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ñ‡∏±‡∏î‡πÑ‡∏õ ‡πÉ‡∏´‡πâ Metadata ‡πÑ‡∏õ‡∏ñ‡∏∂‡∏á‡∏ó‡πâ‡∏≤‡∏¢\n",
        "            meta_content_end = len(body)\n",
        "\n",
        "        # ‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏ï‡πà‡∏≤‡∏á‡πÜ\n",
        "        before_meta = body[:meta_start]\n",
        "        meta_content = body[meta_header_end:meta_content_end]\n",
        "        after_meta = body[meta_content_end:]\n",
        "\n",
        "        # ‡∏•‡∏ö Metadata headers ‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô after_meta\n",
        "        after_meta = re.sub(r'(?m)^###\\s*Metadata\\s*\\n?', '', after_meta)\n",
        "\n",
        "    else:\n",
        "        # ‡πÑ‡∏°‡πà‡∏°‡∏µ Metadata ‡πÄ‡∏•‡∏¢ - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà\n",
        "        before_meta = ''\n",
        "        meta_content = body\n",
        "        after_meta = ''\n",
        "\n",
        "    # === Step 5: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ batch_id ‡πÉ‡∏ô metadata content ===\n",
        "    # ‡∏•‡∏ö‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á‡∏ï‡πâ‡∏ô metadata content\n",
        "    meta_content = meta_content.lstrip('\\n')\n",
        "\n",
        "    if re.search(r'(?m)^\\s*batch_id\\s*:', meta_content):\n",
        "        # ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß - ‡πÅ‡∏Å‡πâ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å\n",
        "        meta_content = re.sub(\n",
        "            r'(?m)^(\\s*batch_id\\s*:\\s*)[^\\n]*',\n",
        "            r'\\g<1>' + BATCH_ID_EXPECT,\n",
        "            meta_content\n",
        "        )\n",
        "    else:\n",
        "        # ‡πÑ‡∏°‡πà‡∏°‡∏µ - ‡πÄ‡∏ï‡∏¥‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á metadata\n",
        "        meta_content = f\"batch_id: {BATCH_ID_EXPECT}\\n\" + meta_content\n",
        "\n",
        "    # === Step 6: ‡πÄ‡∏ï‡∏¥‡∏° tier ‡πÅ‡∏•‡∏∞ model_size ‡∏ó‡πâ‡∏≤‡∏¢ metadata ===\n",
        "    meta_content = meta_content.rstrip()\n",
        "    meta_content += f\"\\ntier: {tier_val}\"\n",
        "    if model_size:\n",
        "        model_size = model_size.upper().replace(' B', 'B')\n",
        "        meta_content += f\"\\nmodel_size: {model_size}\"\n",
        "\n",
        "    # === Step 7: ‡∏•‡∏ö --- ‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡πÉ‡∏ô after_meta ===\n",
        "    after_meta = re.sub(r'(?m)^\\s*---\\s*\\n?', '', after_meta)\n",
        "    after_meta = re.sub(r'(?m)^\\s*#\\s*$\\n?', '', after_meta)  # ‡∏•‡∏ö # ‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß‡πÜ\n",
        "    after_meta = re.sub(r'\\n{3,}', '\\n\\n', after_meta)\n",
        "\n",
        "    # === Step 8: ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö (‡∏õ‡∏£‡∏±‡∏ö spacing) ===\n",
        "    # ### Metadata (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏á‡∏´‡∏±‡∏ß)\n",
        "    # metadata content\n",
        "    # (‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á)\n",
        "    # after_meta content\n",
        "\n",
        "    if first_meta_match or not before_meta:\n",
        "        # Format: ### Metadata\\n<content>\\n\\n<after>\n",
        "        result = before_meta + \"### Metadata\\n\" + meta_content\n",
        "        if after_meta.strip():\n",
        "            result += \"\\n\\n\" + after_meta.lstrip()\n",
        "    else:\n",
        "        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏û‡∏¥‡πÄ‡∏®‡∏© (‡πÑ‡∏°‡πà‡∏ô‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏î)\n",
        "        result = \"### Metadata\\n\" + meta_content\n",
        "        if after_meta.strip():\n",
        "            result += \"\\n\\n\" + after_meta.lstrip()\n",
        "\n",
        "    # === Step 9: ‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ --- ===\n",
        "    result = result.rstrip() + \"\\n\\n---\"\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "EO0LXc_9-_h7"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 3) APPLY FIX TO ALL BLOCKS\n",
        "# ============================================\n",
        "\n",
        "fixed_blocks = [(h, fix_block(b)) for (h, b) in blocks]\n",
        "\n",
        "# ‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå (‡πÄ‡∏ß‡πâ‡∏ô 1 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á blocks)\n",
        "fixed_text = ''\n",
        "for i, (h, b) in enumerate(fixed_blocks):\n",
        "    if i > 0:\n",
        "        fixed_text += '\\n'  # ‡πÄ‡∏ß‡πâ‡∏ô 1 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á blocks\n",
        "    fixed_text += f\"{h}\\n{b}\"\n",
        "\n",
        "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå\n",
        "with open(DST_KEEP_NUM, 'w', encoding='utf-8') as f:\n",
        "    f.write(fixed_text)\n",
        "\n",
        "print(\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå:\", DST_KEEP_NUM)"
      ],
      "metadata": {
        "id": "yqvSH3Rg_DTa",
        "outputId": "9af13407-ff97-4e80-93cf-c0f5ce88e2b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå: /content/drive/MyDrive/Dataset_Curation/causal_batch_01_FIXED_KEEPNUM.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 4) VALIDATE FORMAT\n",
        "# ============================================\n",
        "\n",
        "import collections\n",
        "\n",
        "errors = collections.defaultdict(list)\n",
        "model_sizes = []\n",
        "tier_counts = collections.Counter()\n",
        "\n",
        "for i, (_, b) in enumerate(fixed_blocks, start=1):\n",
        "    # ‡∏ï‡∏£‡∏ß‡∏à batch_id\n",
        "    if f\"batch_id: {BATCH_ID_EXPECT}\" not in b:\n",
        "        errors['batch_id'].append(i)\n",
        "\n",
        "    # ‡∏ï‡∏£‡∏ß‡∏à separator ‡∏ó‡πâ‡∏≤‡∏¢\n",
        "    if not b.strip().endswith('---'):\n",
        "        errors['separator'].append(i)\n",
        "\n",
        "    # ‡∏ï‡∏£‡∏ß‡∏à tier\n",
        "    m_tier = re.search(r'(?m)^\\s*tier\\s*:\\s*([^\\n]+)$', b)\n",
        "    if m_tier:\n",
        "        tier_value = m_tier.group(1).strip()\n",
        "        if re.match(r'^[1-6]$', tier_value):\n",
        "            tier_counts[tier_value] += 1\n",
        "        else:\n",
        "            errors['tier_invalid'].append(i)\n",
        "    else:\n",
        "        errors['tier_missing'].append(i)\n",
        "\n",
        "    # ‡∏ô‡∏±‡∏ö model_size\n",
        "    m_sz = re.search(r'(?m)^\\s*model_size\\s*:\\s*([^\\n]+)$', b)\n",
        "    if m_sz:\n",
        "        model_sizes.append(m_sz.group(1).strip())\n",
        "\n",
        "    # ‡∏ï‡∏£‡∏ß‡∏à Metadata ‡∏ã‡πâ‡∏≥\n",
        "    meta_count = len(re.findall(r'(?m)^###\\s*Metadata\\s*$', b))\n",
        "    if meta_count > 1:\n",
        "        errors['metadata_duplicate'].append(f\"{i} (found {meta_count})\")\n",
        "\n",
        "    # ‡∏ï‡∏£‡∏ß‡∏à spacing ‡∏´‡∏•‡∏±‡∏á Metadata\n",
        "    if '### Metadata\\n\\n' in b:\n",
        "        errors['metadata_spacing'].append(i)\n",
        "\n",
        "print(\"\\nüìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if errors:\n",
        "    print(\"‚ùå ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î:\")\n",
        "    for error_type, block_nums in errors.items():\n",
        "        print(f\"  - {error_type}: blocks {block_nums[:5]}{'...' if len(block_nums) > 5 else ''}\")\n",
        "else:\n",
        "    print(\"‚úÖ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î!\")\n",
        "\n",
        "print(f\"\\nüìà Tier distribution: {dict(tier_counts)}\")\n",
        "print(f\"üì¶ Model sizes found: {sorted(set(model_sizes))}\")\n",
        "print(f\"üìù Total blocks: {len(fixed_blocks)}\")"
      ],
      "metadata": {
        "id": "ChEkcSMr_ESo",
        "outputId": "d667b859-069f-42b2-eb45-9c1df0480789",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö:\n",
            "==================================================\n",
            "‚úÖ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î!\n",
            "\n",
            "üìà Tier distribution: {'2': 100}\n",
            "üì¶ Model sizes found: ['13B', '30B']\n",
            "üìù Total blocks: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 5) PREVIEW FIRST BLOCK\n",
        "# ============================================\n",
        "\n",
        "if fixed_blocks:\n",
        "    print(\"\\nüîç ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Block ‡πÅ‡∏£‡∏Å:\")\n",
        "    print(\"=\" * 50)\n",
        "    preview = fixed_blocks[0][0] + \"\\n\" + fixed_blocks[0][1]\n",
        "    # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà 50 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å\n",
        "    lines = preview.split('\\n')[:50]\n",
        "    print('\\n'.join(lines))\n",
        "    if len(preview.split('\\n')) > 50:\n",
        "        print(\"... (truncated)\")"
      ],
      "metadata": {
        "id": "UOnARzZC_Hjk",
        "outputId": "d97fe3ee-8af0-443c-c7d2-cbebb69fc255",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Block ‡πÅ‡∏£‡∏Å:\n",
            "==================================================\n",
            "## Prompt 1\n",
            "### Metadata\n",
            "prompt_id: causal_reasoning_001  \n",
            "batch_id: causal_batch_01\n",
            "reasoning_type: causal_reasoning  \n",
            "sub_type: direct_cause_effect_identification  \n",
            "difficulty: medium  \n",
            "language: th  \n",
            "domain_context: environmental_policy  \n",
            "contains_statistics: false  \n",
            "has_numerical_estimate: false  \n",
            "requires_visualization: false  \n",
            "symbolic_risk: low  \n",
            "contains_fallacy_risk: false  \n",
            "confidence_level_expected: high  \n",
            "is_behavior_driven: false  \n",
            "concept_tags: [environmental_policy, cause_effect, pollution_control]  \n",
            "fallacy: none  \n",
            "fallacy_type: none  \n",
            "chain_depth: 2  \n",
            "tone_style: formal  \n",
            "self_critique: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå  \n",
            "belief_tracking: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°  \n",
            "eval_standard: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡πÄ‡∏´‡∏ï‡∏∏‡πÅ‡∏•‡∏∞‡∏ú‡∏•  \n",
            "reasoning_path_trace: ‡∏£‡∏∞‡∏ö‡∏∏‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏´‡∏•‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô\n",
            "tier: 2\n",
            "model_size: 13B\n",
            "\n",
            "### Prompt (TH)\n",
            "‡∏ó‡∏≥‡πÑ‡∏°‡∏Ñ‡∏ô‡∏ñ‡∏∂‡∏á‡∏´‡∏≤‡∏ß‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢?\n",
            "\n",
            "### Prompt (EN)\n",
            "Why do people yawn when they are tired?\n",
            "\n",
            "### Prompt (ZH)\n",
            "[‡πÉ‡∏´‡πâ LLM ‡∏à‡∏µ‡∏ô‡πÅ‡∏õ‡∏•‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ]\n",
            "\n",
            "### Reasoning\n",
            "(TH) ‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏≠‡∏≠‡∏Å‡∏ã‡∏¥‡πÄ‡∏à‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏¢‡∏∑‡∏î‡∏Å‡∏•‡πâ‡∏≤‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢‡πÄ‡∏Å‡∏¥‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢‡∏•‡πâ‡∏≤ ‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏à‡∏∞‡∏™‡πà‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏≠‡∏≠‡∏Å‡∏ã‡∏¥‡πÄ‡∏à‡∏ô‡πÉ‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢‡∏ï‡∏∑‡πà‡∏ô‡∏ï‡∏±‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡∏≠‡∏µ‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏¢‡∏±‡∏á‡∏≠‡∏≤‡∏à‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏™‡∏°‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó  \n",
            "(EN) Yawning is a process that increases oxygen intake and stretches facial muscles. When the body is fatigued, the nervous system triggers yawning to balance oxygen levels in the blood and provide a temporary boost in alertness. It may also help cool the brain and maintain neural efficiency.  \n",
            "(ZH) [‡πÉ‡∏´‡πâ LLM ‡∏à‡∏µ‡∏ô‡πÅ‡∏õ‡∏•‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ]\n",
            "\n",
            "### Rejected Reasoning\n",
            "(TH) ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç ‚Äî **fallacy: false cause** ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏≤‡∏á‡∏ä‡∏µ‡∏ß‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö  \n",
            "(EN) Because yawning is a sign of happiness ‚Äî **fallacy: false cause**, as it assumes a causal link based on subjective belief without biological evidence.  \n",
            "(ZH) [‡πÉ‡∏´‡πâ LLM ‡∏à‡∏µ‡∏ô‡πÅ‡∏õ‡∏•‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ]\n",
            "\n",
            "### Chosen Answer\n",
            "(TH) ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏ß‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏≠‡∏≠‡∏Å‡∏ã‡∏¥‡πÄ‡∏à‡∏ô‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡∏∑‡πà‡∏ô‡∏ï‡∏±‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô  \n",
            "(EN) Because yawning increases oxygen and helps keep you alert  \n",
            "... (truncated)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}