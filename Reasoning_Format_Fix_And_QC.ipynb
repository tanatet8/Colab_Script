{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanatet8/Colab_Script/blob/main/Reasoning_Format_Fix_And_QC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# FORMAT FIXER COMPLETE VERSION - For Colab\n",
        "# แก้ไขครบทุกปัญหาที่พบ - แบ่ง Cell ชัดเจน\n",
        "# ============================================\n",
        "\n",
        "# %% [markdown]\n",
        "# # Format Fixer Complete - แก้ไข MD Files ให้มี Format สมบูรณ์\n",
        "\n",
        "# %%\n",
        "# ============================================\n",
        "# Cell 1: Mount Drive & Import Libraries\n",
        "# ============================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import re\n",
        "import collections\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"✅ Libraries imported\")"
      ],
      "metadata": {
        "id": "DOnJ2n7bQ5f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# ============================================\n",
        "# Cell 2: Configuration - แก้ Path ตรงนี้\n",
        "# ============================================\n",
        "\n",
        "# ✏️ ตั้งพาธไฟล์ของคุณ\n",
        "SRC = '/content/drive/MyDrive/Dataset_Curation/causal_batch_01.md'\n",
        "DST_FIXED = SRC.replace('.md', '_FIXED_COMPLETE.md')\n",
        "\n",
        "# Batch id ที่ถูกต้อง\n",
        "BATCH_ID_EXPECT = 'causal_batch_01'\n",
        "\n",
        "print(\"🎯 Configuration loaded\")\n",
        "print(f\"Source: {SRC}\")\n",
        "print(f\"Output: {DST_FIXED}\")\n",
        "\n",
        "# %%\n",
        "# ============================================\n",
        "# Cell 3: Define Mappings & Constants\n",
        "# ============================================\n",
        "\n",
        "# Canonical names สำหรับ reasoning_type (แปลง alias → ชื่อมาตรฐาน)\n",
        "REASONING_TYPE_CANONICAL = {\n",
        "    # Aliases → Canonical name\n",
        "    'causal': 'causal_reasoning',\n",
        "    'counterfactual': 'counterfactual_reasoning',\n",
        "    'symbolic': 'symbolic_reasoning',\n",
        "    'deductive': 'deductive_reasoning',\n",
        "    'meta': 'meta_reasoning',\n",
        "    'probabilistic': 'probabilistic_reasoning',\n",
        "    'commonsense': 'commonsense_reasoning',\n",
        "    'analogical': 'analogical_reasoning',\n",
        "    'temporal': 'temporal_reasoning',\n",
        "    'spatial': 'spatial_reasoning',\n",
        "}\n",
        "\n",
        "# Tier mapping\n",
        "TIER_MAPPING = {\n",
        "    # Tier 1\n",
        "    'symbolic_reasoning': 1, 'deductive_reasoning': 1,\n",
        "    'if_then_only_if_iff': 1, 'contrapositive_xor': 1,\n",
        "    'contradiction_trap': 1, 'logic_trap': 1, 'fallacy_detection': 1,\n",
        "    'symbolic_recursion': 1, 'logic_tree': 1, 'belief_modeling': 1,\n",
        "\n",
        "    # Tier 2\n",
        "    'causal_reasoning': 2, 'counterfactual_reasoning': 2,\n",
        "    'emotional_behavioral_cause': 2, 'daily_life_reasoning': 2,\n",
        "    'temporal_reasoning': 2, 'spatial_reasoning': 2,\n",
        "    'probabilistic_reasoning': 2, 'commonsense_reasoning': 2,\n",
        "\n",
        "    # Tier 3\n",
        "    'meta_reasoning': 3, 'ambiguity_detection': 3,\n",
        "    'ambiguity_resolution': 3, 'weak_evidence_uncertainty': 3,\n",
        "    'language_driven_inference': 3, 'structural_analogy': 3,\n",
        "    'multi_hop_justification': 3,\n",
        "\n",
        "    # Tier 4\n",
        "    'belief_revision': 4, 'epistemic_reasoning': 4,\n",
        "    'self_consistency_logic': 4, 'ontological_shift': 4,\n",
        "\n",
        "    # Tier 5\n",
        "    'multi_agent_simulation': 5, 'perspective_reasoning': 5,\n",
        "    'recursive_inference': 5, 'perspective_clash': 5,\n",
        "\n",
        "    # Tier 6\n",
        "    'moral_ambiguity_tradeoff': 6, 'identity_loop_reasoning': 6,\n",
        "    'ethical_dilemma_decomposition': 6, 'planning_goal_based_reasoning': 6,\n",
        "    'deontic_reasoning': 6, 'narrative_causal_reasoning': 6,\n",
        "    'philosophical_logic': 6, 'analogical_reasoning': 6,\n",
        "    'heuristic_reasoning': 6, 'multi_lingual_reasoning': 6,\n",
        "}\n",
        "\n",
        "print(f\"✅ Loaded {len(REASONING_TYPE_CANONICAL)} canonical mappings\")\n",
        "print(f\"✅ Loaded {len(TIER_MAPPING)} tier mappings\")"
      ],
      "metadata": {
        "id": "O4GQ9sN_Q-q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# ============================================\n",
        "# Cell 4: Define Metadata Field Order\n",
        "# ============================================\n",
        "\n",
        "# Metadata fields ที่ต้องมี (ตามลำดับ)\n",
        "REQUIRED_METADATA_FIELDS = [\n",
        "    'prompt_id',\n",
        "    'batch_id',\n",
        "    'reasoning_type',\n",
        "    'sub_type',\n",
        "    'difficulty',\n",
        "    'language',\n",
        "    'domain_context',\n",
        "    'tier',\n",
        "    'model_size'\n",
        "]\n",
        "\n",
        "# Optional metadata fields (เรียงตามลำดับถ้ามี)\n",
        "OPTIONAL_METADATA_FIELDS = [\n",
        "    'contains_statistics',\n",
        "    'has_numerical_estimate',\n",
        "    'requires_visualization',\n",
        "    'symbolic_risk',\n",
        "    'contains_fallacy_risk',\n",
        "    'confidence_level_expected',\n",
        "    'is_behavior_driven',\n",
        "    'concept_tags',\n",
        "    'fallacy',\n",
        "    'fallacy_type',\n",
        "    'chain_depth',\n",
        "    'tone_style',\n",
        "    'self_critique',\n",
        "    'belief_tracking',\n",
        "    'eval_standard',\n",
        "    'reasoning_path_trace'\n",
        "]\n",
        "\n",
        "print(f\"✅ Required fields: {len(REQUIRED_METADATA_FIELDS)}\")\n",
        "print(f\"✅ Optional fields: {len(OPTIONAL_METADATA_FIELDS)}\")"
      ],
      "metadata": {
        "id": "jw_c0JGgRC0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# ============================================\n",
        "# Cell 5: Helper Functions - Basic\n",
        "# ============================================\n",
        "\n",
        "def normalize_reasoning_type(rtype: str) -> str:\n",
        "    \"\"\"Normalize reasoning type to canonical name\"\"\"\n",
        "    rtype = rtype.strip().lower()\n",
        "\n",
        "    # Check if it's an alias\n",
        "    if rtype in REASONING_TYPE_CANONICAL:\n",
        "        return REASONING_TYPE_CANONICAL[rtype]\n",
        "\n",
        "    # Already canonical or unknown\n",
        "    return rtype\n",
        "\n",
        "def infer_tier(reasoning_type: str) -> str:\n",
        "    \"\"\"Infer tier from reasoning type\"\"\"\n",
        "    rtype = reasoning_type.strip().lower()\n",
        "\n",
        "    if rtype in TIER_MAPPING:\n",
        "        return str(TIER_MAPPING[rtype])\n",
        "\n",
        "    # Check canonical name\n",
        "    canonical = normalize_reasoning_type(rtype)\n",
        "    if canonical in TIER_MAPPING:\n",
        "        return str(TIER_MAPPING[canonical])\n",
        "\n",
        "    return '2'  # Default\n",
        "\n",
        "def parse_metadata(meta_text: str) -> dict:\n",
        "    \"\"\"Parse metadata text into dictionary\"\"\"\n",
        "    metadata = {}\n",
        "\n",
        "    for line in meta_text.split('\\n'):\n",
        "        if ':' in line:\n",
        "            key, value = line.split(':', 1)\n",
        "            key = key.strip()\n",
        "            value = value.strip()\n",
        "\n",
        "            # Special handling for boolean values\n",
        "            if value.lower() in ['true', 'false']:\n",
        "                value = value.lower()\n",
        "\n",
        "            metadata[key] = value\n",
        "\n",
        "    return metadata\n",
        "\n",
        "print(\"✅ Basic helper functions defined\")"
      ],
      "metadata": {
        "id": "5tdx6OQ5RHtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# ============================================\n",
        "# Cell 6: Helper Functions - Formatting\n",
        "# ============================================\n",
        "\n",
        "def format_metadata(metadata: dict, prompt_num: int) -> str:\n",
        "    \"\"\"Format metadata with correct order and values\"\"\"\n",
        "    formatted = []\n",
        "\n",
        "    # Normalize prompt_id\n",
        "    if 'prompt_id' not in metadata or not metadata['prompt_id']:\n",
        "        metadata['prompt_id'] = f\"{BATCH_ID_EXPECT}_p{prompt_num:03d}\"\n",
        "    elif not metadata['prompt_id'].startswith(BATCH_ID_EXPECT):\n",
        "        # Extract number and reformat\n",
        "        num_match = re.search(r'\\d+', metadata['prompt_id'])\n",
        "        if num_match:\n",
        "            num = num_match.group()\n",
        "            metadata['prompt_id'] = f\"{BATCH_ID_EXPECT}_p{int(num):03d}\"\n",
        "\n",
        "    # Ensure batch_id is correct\n",
        "    metadata['batch_id'] = BATCH_ID_EXPECT\n",
        "\n",
        "    # Normalize reasoning_type\n",
        "    if 'reasoning_type' in metadata:\n",
        "        metadata['reasoning_type'] = normalize_reasoning_type(metadata['reasoning_type'])\n",
        "\n",
        "    # Ensure tier exists and normalize model_size\n",
        "    if 'tier' not in metadata:\n",
        "        if 'reasoning_type' in metadata:\n",
        "            metadata['tier'] = infer_tier(metadata['reasoning_type'])\n",
        "        else:\n",
        "            metadata['tier'] = '2'\n",
        "\n",
        "    # Check if tier value is actually model_size (e.g., \"13B\")\n",
        "    if 'tier' in metadata:\n",
        "        tier_val = str(metadata['tier'])\n",
        "        if 'B' in tier_val.upper():\n",
        "            metadata['model_size'] = tier_val.upper()\n",
        "            metadata['tier'] = infer_tier(metadata.get('reasoning_type', ''))\n",
        "        elif tier_val.isdigit() and int(tier_val) > 6:\n",
        "            metadata['model_size'] = f\"{tier_val}B\"\n",
        "            metadata['tier'] = infer_tier(metadata.get('reasoning_type', ''))\n",
        "\n",
        "    # Add required fields first (in order)\n",
        "    for field in REQUIRED_METADATA_FIELDS:\n",
        "        if field in metadata:\n",
        "            formatted.append(f\"{field}: {metadata[field]}\")\n",
        "        elif field == 'batch_id':\n",
        "            formatted.append(f\"batch_id: {BATCH_ID_EXPECT}\")\n",
        "        elif field == 'tier':\n",
        "            formatted.append(f\"tier: 2\")\n",
        "\n",
        "    # Add optional fields (in order)\n",
        "    for field in OPTIONAL_METADATA_FIELDS:\n",
        "        if field in metadata:\n",
        "            formatted.append(f\"{field}: {metadata[field]}\")\n",
        "\n",
        "    # Add any remaining fields not in our lists\n",
        "    processed_fields = set(REQUIRED_METADATA_FIELDS + OPTIONAL_METADATA_FIELDS)\n",
        "    for key, value in metadata.items():\n",
        "        if key not in processed_fields:\n",
        "            formatted.append(f\"{key}: {value}\")\n",
        "\n",
        "    return '\\n'.join(formatted)\n",
        "\n",
        "print(\"✅ Formatting functions defined\")"
      ],
      "metadata": {
        "id": "XI2pPHynRMHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# ============================================\n",
        "# Cell 7: Helper Functions - Content Processing\n",
        "# ============================================\n",
        "\n",
        "def fix_multilang_section(text: str, section_header: str) -> str:\n",
        "    \"\"\"Fix multi-language section format\"\"\"\n",
        "\n",
        "    # Find the section\n",
        "    pattern = rf'({section_header}\\s*\\n)(.*?)(?=\\n###|\\n---|\\Z)'\n",
        "    match = re.search(pattern, text, re.DOTALL)\n",
        "\n",
        "    if not match:\n",
        "        return text\n",
        "\n",
        "    section_content = match.group(2)\n",
        "\n",
        "    # Check if it has proper (TH), (EN), (ZH) format\n",
        "    has_th = '(TH)' in section_content or '**TH**:' in section_content\n",
        "    has_en = '(EN)' in section_content or '**EN**:' in section_content\n",
        "\n",
        "    # Convert **TH**: format to (TH) format\n",
        "    if '**TH**:' in section_content or '**EN**:' in section_content:\n",
        "        section_content = section_content.replace('**TH**:', '(TH)')\n",
        "        section_content = section_content.replace('**EN**:', '(EN)')\n",
        "        section_content = section_content.replace('**ZH**:', '(ZH)')\n",
        "\n",
        "    if not has_th and not has_en:\n",
        "        # Assume it's Thai if no language markers\n",
        "        fixed_content = f\"(TH) {section_content.strip()}\\n\"\n",
        "        fixed_content += \"(EN) [To be translated]\\n\"\n",
        "        fixed_content += \"(ZH) [To be translated]\"\n",
        "\n",
        "        text = text[:match.start(2)] + fixed_content + text[match.end(2):]\n",
        "\n",
        "    return text\n",
        "\n",
        "print(\"✅ Content processing functions defined\")"
      ],
      "metadata": {
        "id": "CifhfVdCRPX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# ============================================\n",
        "# Cell 8: Main Fix Block Function\n",
        "# ============================================\n",
        "\n",
        "def fix_block_complete(header: str, body: str, prompt_num: int) -> tuple:\n",
        "    \"\"\"Complete fix for a single block\"\"\"\n",
        "\n",
        "    # Step 1: Clean up everything before Metadata\n",
        "    body = re.sub(r'^[\\s\\-#]*\\n*', '', body)\n",
        "\n",
        "    # Step 2: Extract and process Metadata\n",
        "    meta_match = re.search(r'###\\s*Metadata\\s*\\n(.*?)(?=\\n###|\\n##|$)', body, re.DOTALL)\n",
        "\n",
        "    if meta_match:\n",
        "        meta_start = meta_match.start()\n",
        "        meta_end = meta_match.end()\n",
        "        meta_content = meta_match.group(1)\n",
        "        before_meta = body[:meta_start]\n",
        "        after_meta = body[meta_end:]\n",
        "    else:\n",
        "        # No metadata found - create section\n",
        "        meta_content = \"\"\n",
        "        before_meta = \"\"\n",
        "        after_meta = body\n",
        "\n",
        "    # Parse metadata\n",
        "    metadata = parse_metadata(meta_content)\n",
        "\n",
        "    # Clean up duplicate Metadata headers in after_meta\n",
        "    after_meta = re.sub(r'###\\s*Metadata\\s*\\n', '', after_meta)\n",
        "\n",
        "    # Remove tier/model_size from after_meta (they should only be in metadata)\n",
        "    after_meta = re.sub(r'(?m)^\\s*tier\\s*:.*\\n?', '', after_meta)\n",
        "    after_meta = re.sub(r'(?m)^\\s*model_size\\s*:.*\\n?', '', after_meta)\n",
        "\n",
        "    # Step 3: Process content sections\n",
        "    # Clean up --- in the middle of content\n",
        "    after_meta = re.sub(r'(?m)^\\s*---\\s*\\n?', '', after_meta)\n",
        "\n",
        "    # Ensure proper structure for multi-language content\n",
        "    after_meta = fix_multilang_section(after_meta, '### Reasoning')\n",
        "    after_meta = fix_multilang_section(after_meta, '### Rejected Reasoning')\n",
        "    after_meta = fix_multilang_section(after_meta, '### Chosen Answer')\n",
        "    after_meta = fix_multilang_section(after_meta, '### Explanation')\n",
        "\n",
        "    # Step 4: Reconstruct block\n",
        "    # Format metadata with correct order\n",
        "    formatted_metadata = format_metadata(metadata, prompt_num)\n",
        "\n",
        "    # Build final block\n",
        "    result = \"### Metadata\\n\"\n",
        "    result += formatted_metadata\n",
        "    result += \"\\n\\n\"  # Two newlines after metadata\n",
        "    result += after_meta.lstrip()\n",
        "\n",
        "    # Clean up multiple newlines\n",
        "    result = re.sub(r'\\n{3,}', '\\n\\n', result)\n",
        "\n",
        "    # Ensure ends with ---\n",
        "    result = result.rstrip() + \"\\n\\n---\"\n",
        "\n",
        "    return header, result\n",
        "\n",
        "print(\"✅ Main fix function defined\")"
      ],
      "metadata": {
        "id": "pTTSEFCNRUra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# ============================================\n",
        "# Cell 9: Load and Process File\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n📂 Loading file...\")\n",
        "with open(SRC, 'r', encoding='utf-8') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Split into blocks\n",
        "print(\"✂️ Splitting into blocks...\")\n",
        "parts = re.split(r'(##\\s*Prompt\\s+\\d+[^\\n]*\\n)', content)\n",
        "\n",
        "blocks = []\n",
        "for i in range(1, len(parts), 2):\n",
        "    if i+1 < len(parts):\n",
        "        header = parts[i].rstrip('\\n')\n",
        "        body = parts[i+1]\n",
        "\n",
        "        # Extract prompt number\n",
        "        num_match = re.search(r'Prompt\\s+(\\d+)', header)\n",
        "        prompt_num = int(num_match.group(1)) if num_match else i//2 + 1\n",
        "\n",
        "        blocks.append((header, body, prompt_num))\n",
        "\n",
        "print(f\"📦 Found {len(blocks)} blocks\")"
      ],
      "metadata": {
        "id": "SzFi3kOyRZle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# ============================================\n",
        "# Cell 10: Fix All Blocks\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n🔧 Fixing blocks...\")\n",
        "fixed_blocks = []\n",
        "\n",
        "for header, body, prompt_num in blocks:\n",
        "    fixed_header, fixed_body = fix_block_complete(header, body, prompt_num)\n",
        "    fixed_blocks.append((fixed_header, fixed_body))\n",
        "\n",
        "    # Show progress every 10 blocks\n",
        "    if prompt_num % 10 == 0:\n",
        "        print(f\"  Processing block {prompt_num}...\")\n",
        "\n",
        "print(f\"✅ Fixed {len(fixed_blocks)} blocks\")"
      ],
      "metadata": {
        "id": "q_s4nC_KRcyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# ============================================\n",
        "# Cell 11: Combine and Save\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n📝 Combining blocks...\")\n",
        "fixed_content = \"\"\n",
        "for i, (header, body) in enumerate(fixed_blocks):\n",
        "    if i > 0:\n",
        "        fixed_content += \"\\n\"  # Single newline between blocks\n",
        "    fixed_content += f\"{header}\\n{body}\"\n",
        "\n",
        "# Save file\n",
        "print(f\"💾 Saving to {DST_FIXED}\")\n",
        "with open(DST_FIXED, 'w', encoding='utf-8') as f:\n",
        "    f.write(fixed_content)\n",
        "\n",
        "print(\"✅ File saved!\")"
      ],
      "metadata": {
        "id": "F-96wCBSRfUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# ============================================\n",
        "# Cell 12: Validation\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n🔍 Validating fixed file...\")\n",
        "\n",
        "errors = collections.defaultdict(list)\n",
        "stats = collections.defaultdict(int)\n",
        "\n",
        "for i, (header, body) in enumerate(fixed_blocks, 1):\n",
        "    # Check batch_id\n",
        "    if f\"batch_id: {BATCH_ID_EXPECT}\" not in body:\n",
        "        errors['batch_id'].append(i)\n",
        "\n",
        "    # Check prompt_id format\n",
        "    if not re.search(rf'prompt_id:\\s*{BATCH_ID_EXPECT}_p\\d{{3}}', body):\n",
        "        errors['prompt_id_format'].append(i)\n",
        "\n",
        "    # Check separator\n",
        "    if not body.strip().endswith('---'):\n",
        "        errors['separator'].append(i)\n",
        "\n",
        "    # Check tier\n",
        "    tier_match = re.search(r'(?m)^\\s*tier\\s*:\\s*([^\\n]+)$', body)\n",
        "    if tier_match:\n",
        "        tier = tier_match.group(1).strip()\n",
        "        if tier in ['1','2','3','4','5','6']:\n",
        "            stats[f'tier_{tier}'] += 1\n",
        "        else:\n",
        "            errors['tier_invalid'].append(i)\n",
        "    else:\n",
        "        errors['tier_missing'].append(i)\n",
        "\n",
        "    # Check reasoning_type normalization\n",
        "    rtype_match = re.search(r'(?m)^\\s*reasoning_type\\s*:\\s*([^\\n]+)$', body)\n",
        "    if rtype_match:\n",
        "        rtype = rtype_match.group(1).strip()\n",
        "        stats[f'type_{rtype}'] += 1\n",
        "\n",
        "print(\"\\n📊 Validation Results:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "if errors:\n",
        "    print(\"❌ Issues found:\")\n",
        "    for error_type, blocks in errors.items():\n",
        "        print(f\"  {error_type}: {len(blocks)} blocks\")\n",
        "        if len(blocks) <= 5:\n",
        "            print(f\"    Blocks: {blocks}\")\n",
        "else:\n",
        "    print(\"✅ No issues found!\")\n",
        "\n",
        "print(\"\\n📈 Statistics:\")\n",
        "print(f\"  Total blocks: {len(fixed_blocks)}\")\n",
        "\n",
        "# Show tier distribution\n",
        "tier_dist = {k: v for k, v in stats.items() if k.startswith('tier_')}\n",
        "if tier_dist:\n",
        "    print(\"  Tier distribution:\")\n",
        "    for tier, count in sorted(tier_dist.items()):\n",
        "        print(f\"    {tier}: {count}\")\n",
        "\n",
        "# Show type distribution (top 10)\n",
        "type_dist = {k: v for k, v in stats.items() if k.startswith('type_')}\n",
        "if type_dist:\n",
        "    print(\"  Top reasoning types:\")\n",
        "    for rtype, count in sorted(type_dist.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "        print(f\"    {rtype.replace('type_', '')}: {count}\")"
      ],
      "metadata": {
        "id": "ALFYKHBCRjcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# ============================================\n",
        "# Cell 13: Preview Sample Output\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n👁️ Preview of first fixed block:\")\n",
        "print(\"=\"*50)\n",
        "if fixed_blocks:\n",
        "    preview = fixed_blocks[0][0] + \"\\n\" + fixed_blocks[0][1]\n",
        "    lines = preview.split('\\n')[:30]  # Show first 30 lines\n",
        "    for line in lines:\n",
        "        print(line)\n",
        "    if len(preview.split('\\n')) > 30:\n",
        "        print(\"... (truncated)\")\n",
        "\n",
        "print(\"\\n✅ COMPLETE! File saved to:\", DST_FIXED)"
      ],
      "metadata": {
        "id": "JCJgILipRmQq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "ยินดีต้อนรับสู่ Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}