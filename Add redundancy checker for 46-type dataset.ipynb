{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanatet8/Colab_Script/blob/main/Add%20redundancy%20checker%20for%2046-type%20dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 1: Setup & Mount\n",
        "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ + Mount Google Drive\n",
        "# ============================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install -q pandas numpy scikit-learn matplotlib seaborn openpyxl tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import re\n",
        "import json\n",
        "from collections import Counter, defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "mPeSsVT2gy77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 2: Configuration\n",
        "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å ‡πÄ‡∏ä‡πà‡∏ô path, batch size, threshold\n",
        "# ============================================\n",
        "class Config:\n",
        "    # Paths - ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô path dataset ‡πÅ‡∏•‡∏∞‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•\n",
        "    DATASET_DIR = '/content/drive/MyDrive/Dataset_Curation'\n",
        "    OUTPUT_DIR = '/content/drive/MyDrive/Dataset_Curation/redundancy_reports'\n",
        "\n",
        "    # Processing\n",
        "    BATCH_SIZE = 500  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô prompt ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ï‡πà‡∏≠ batch\n",
        "    MAX_PROMPTS = None  # None = ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏™‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î\n",
        "\n",
        "    # Redundancy Thresholds by Type & Tier\n",
        "    THRESHOLDS = {\n",
        "        # Type: [Tier1-2, Tier3-4, Tier5-6]\n",
        "        'causal_reasoning': [0.75, 0.60, 0.40],\n",
        "        'symbolic_reasoning': [0.70, 0.55, 0.35],\n",
        "        'meta_reasoning': [0.60, 0.45, 0.30],\n",
        "        'moral_ambiguity_tradeoff': [0.50, 0.35, 0.25],\n",
        "        'philosophical_logic': [0.45, 0.30, 0.20],\n",
        "        # Default ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö type ‡∏≠‡∏∑‡πà‡∏ô ‡πÜ\n",
        "        'default': [0.65, 0.50, 0.35]\n",
        "    }"
      ],
      "metadata": {
        "id": "RjNEQ60Gg2RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 3: Data Extraction\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå markdown, ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• metadata ‡πÅ‡∏•‡∏∞ prompt\n",
        "# ============================================\n",
        "class DataExtractor:\n",
        "    @staticmethod\n",
        "    def parse_block(block_text):\n",
        "        \"\"\"Extract data ‡∏à‡∏≤‡∏Å 1 block ‡∏Ç‡∏≠‡∏á prompt\"\"\"\n",
        "        data = {}\n",
        "\n",
        "        # Metadata section\n",
        "        meta_match = re.search(r'###\\s*Metadata\\s*\\n(.*?)(?=\\n###|\\n##|$)',\n",
        "                              block_text, re.DOTALL)\n",
        "        if meta_match:\n",
        "            for line in meta_match.group(1).split('\\n'):\n",
        "                if ':' in line:\n",
        "                    key, value = line.split(':', 1)\n",
        "                    data[key.strip()] = value.strip()\n",
        "\n",
        "        # Prompts (TH, EN, ZH)\n",
        "        for lang in ['TH', 'EN', 'ZH']:\n",
        "            pattern = rf'###?\\s*Prompt\\s*\\({lang}\\)\\s*\\n(.*?)(?=\\n###|\\n##|$)'\n",
        "            match = re.search(pattern, block_text, re.DOTALL)\n",
        "            if match:\n",
        "                data[f'prompt_{lang.lower()}'] = match.group(1).strip()\n",
        "\n",
        "        # Reasoning\n",
        "        reason_match = re.search(r'###\\s*Reasoning\\s*\\n(.*?)(?=\\n###|$)',\n",
        "                                block_text, re.DOTALL)\n",
        "        if reason_match:\n",
        "            data['reasoning'] = reason_match.group(1).strip()\n",
        "\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def load_all_files(dataset_dir, max_prompts=None):\n",
        "        \"\"\"‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå MD ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\"\"\"\n",
        "        all_prompts = []\n",
        "        md_files = sorted(Path(dataset_dir).glob('*_batch_*.md'))\n",
        "\n",
        "        print(f\"üìÇ ‡∏û‡∏ö {len(md_files)} batch files\")\n",
        "\n",
        "        for file_path in tqdm(md_files, desc=\"Loading files\"):\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # ‡πÅ‡∏ö‡πà‡∏á‡πÇ‡∏î‡∏¢ ## Prompt N\n",
        "            blocks = re.split(r'##\\s*Prompt\\s+\\d+', content)[1:]\n",
        "\n",
        "            for i, block in enumerate(blocks):\n",
        "                if max_prompts and len(all_prompts) >= max_prompts:\n",
        "                    break\n",
        "\n",
        "                prompt_data = DataExtractor.parse_block(block)\n",
        "                prompt_data['file'] = file_path.name\n",
        "                prompt_data['prompt_id'] = f\"{file_path.stem}_p{i+1:03d}\"\n",
        "                all_prompts.append(prompt_data)\n",
        "\n",
        "            if max_prompts and len(all_prompts) >= max_prompts:\n",
        "                break\n",
        "\n",
        "        return pd.DataFrame(all_prompts)"
      ],
      "metadata": {
        "id": "AzLPfcv7g4mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 4: Redundancy Analysis\n",
        "# ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á prompt ‡∏î‡πâ‡∏ß‡∏¢ TF-IDF + cosine similarity\n",
        "# ============================================\n",
        "class RedundancyAnalyzer:\n",
        "    def __init__(self, df, config):\n",
        "        self.df = df\n",
        "        self.config = config\n",
        "        self.similarity_matrices = {}\n",
        "\n",
        "    def get_threshold(self, reasoning_type, tier):\n",
        "        \"\"\"‡∏î‡∏∂‡∏á threshold ‡∏ï‡∏≤‡∏° reasoning_type ‡πÅ‡∏•‡∏∞ tier\"\"\"\n",
        "        tier_idx = min((tier-1)//2, 2)\n",
        "        if reasoning_type in self.config.THRESHOLDS:\n",
        "            thresholds = self.config.THRESHOLDS[reasoning_type]\n",
        "        else:\n",
        "            thresholds = self.config.THRESHOLDS['default']\n",
        "        return thresholds[tier_idx]\n",
        "\n",
        "    def calculate_similarity_batch(self, df_batch, text_col='prompt_en'):\n",
        "        \"\"\"‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì similarity ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö batch\"\"\"\n",
        "        valid_df = df_batch[df_batch[text_col].notna()].reset_index(drop=True)\n",
        "        if len(valid_df) < 2:\n",
        "            return None, []\n",
        "\n",
        "        # TF-IDF\n",
        "        vectorizer = TfidfVectorizer(\n",
        "            max_features=500,\n",
        "            ngram_range=(1, 3),\n",
        "            min_df=2,\n",
        "            max_df=0.95\n",
        "        )\n",
        "        tfidf_matrix = vectorizer.fit_transform(valid_df[text_col])\n",
        "        sim_matrix = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "        # ‡∏´‡∏≤ pair ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏ô threshold\n",
        "        pairs = []\n",
        "        for i in range(len(sim_matrix)):\n",
        "            for j in range(i+1, len(sim_matrix)):\n",
        "                row_i = valid_df.iloc[i]\n",
        "                row_j = valid_df.iloc[j]\n",
        "                tier_i = int(row_i.get('tier', 2))\n",
        "                tier_j = int(row_j.get('tier', 2))\n",
        "                type_i = row_i.get('reasoning_type', 'default')\n",
        "                threshold = self.get_threshold(type_i, max(tier_i, tier_j))\n",
        "\n",
        "                if sim_matrix[i][j] >= threshold:\n",
        "                    pairs.append({\n",
        "                        'idx1': i,\n",
        "                        'idx2': j,\n",
        "                        'prompt1_id': row_i['prompt_id'],\n",
        "                        'prompt2_id': row_j['prompt_id'],\n",
        "                        'similarity': sim_matrix[i][j],\n",
        "                        'threshold_used': threshold,\n",
        "                        'type1': type_i,\n",
        "                        'type2': row_j.get('reasoning_type', 'default'),\n",
        "                        'tier1': tier_i,\n",
        "                        'tier2': tier_j,\n",
        "                        'prompt1': row_i[text_col][:100],\n",
        "                        'prompt2': row_j[text_col][:100]\n",
        "                    })\n",
        "        return sim_matrix, pairs\n",
        "\n",
        "    def analyze_all(self):\n",
        "        \"\"\"‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏∏‡∏Å prompt ‡πÉ‡∏ô batch\"\"\"\n",
        "        all_pairs = []\n",
        "        batch_size = self.config.BATCH_SIZE\n",
        "        n_batches = (len(self.df) + batch_size - 1) // batch_size\n",
        "\n",
        "        for batch_idx in tqdm(range(n_batches), desc=\"Analyzing batches\"):\n",
        "            start = batch_idx * batch_size\n",
        "            end = min(start + batch_size, len(self.df))\n",
        "            df_batch = self.df.iloc[start:end]\n",
        "            _, pairs = self.calculate_similarity_batch(df_batch)\n",
        "            all_pairs.extend(pairs)\n",
        "\n",
        "        return all_pairs\n",
        "\n",
        "    def get_distribution_stats(self):\n",
        "        \"\"\"‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\"\"\"\n",
        "        stats = {}\n",
        "        categories = ['reasoning_type', 'sub_type', 'domain_context', 'difficulty', 'tier']\n",
        "\n",
        "        for cat in categories:\n",
        "            if cat in self.df.columns:\n",
        "                value_counts = self.df[cat].value_counts()\n",
        "                stats[cat] = {\n",
        "                    'distribution': value_counts.to_dict(),\n",
        "                    'unique': len(value_counts),\n",
        "                    'max': value_counts.max(),\n",
        "                    'min': value_counts.min(),\n",
        "                    'std': value_counts.std(),\n",
        "                    'imbalance_ratio': value_counts.max() / value_counts.min() if value_counts.min() > 0 else float('inf')\n",
        "                }\n",
        "        return stats"
      ],
      "metadata": {
        "id": "GX5XQeb_hIyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 5: Fix Suggestions\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏π‡πà prompt ‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥ (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÇ‡∏î‡πÄ‡∏°‡∏ô/‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô/‡∏°‡∏∏‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°)\n",
        "# ============================================\n",
        "class RedundancyFixer:\n",
        "    @staticmethod\n",
        "    def suggest_fixes(similar_pairs):\n",
        "        \"\"\"Suggest fixes for redundant pairs\"\"\"\n",
        "        suggestions = []\n",
        "\n",
        "        for pair in similar_pairs:\n",
        "            fix_options = []\n",
        "\n",
        "            # Domain shift suggestion\n",
        "            if pair['similarity'] > 0.9:\n",
        "                fix_options.append({\n",
        "                    'method': 'domain_shift',\n",
        "                    'priority': 'high',\n",
        "                    'description': 'Change domain context completely'\n",
        "                })\n",
        "\n",
        "            # Complexity change\n",
        "            if pair['tier1'] == pair['tier2']:\n",
        "                fix_options.append({\n",
        "                    'method': 'complexity_change',\n",
        "                    'priority': 'medium',\n",
        "                    'description': f'Adjust complexity (current tier: {pair[\"tier1\"]})'\n",
        "                })\n",
        "\n",
        "            # Angle change\n",
        "            if 0.7 < pair['similarity'] <= 0.9:\n",
        "                fix_options.append({\n",
        "                    'method': 'angle_change',\n",
        "                    'priority': 'medium',\n",
        "                    'description': 'Change questioning angle or framing'\n",
        "                })\n",
        "\n",
        "            suggestions.append({\n",
        "                'pair': pair,\n",
        "                'fixes': fix_options\n",
        "            })\n",
        "\n",
        "        return suggestions"
      ],
      "metadata": {
        "id": "sGVpdfJBhPNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 6: Report Generation\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô Excel ‡∏Ñ‡∏£‡∏ö‡∏ä‡∏∏‡∏î + ‡∏´‡∏≤ coverage gaps\n",
        "# ============================================\n",
        "class ReportGenerator:\n",
        "    @staticmethod\n",
        "    def create_excel_report(df, similar_pairs, stats, suggestions, output_path):\n",
        "        \"\"\"Generate comprehensive Excel report\"\"\"\n",
        "\n",
        "        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
        "            # Sheet 1: Overview\n",
        "            overview_data = {\n",
        "                'Metric': ['Total Prompts', 'Redundant Pairs', 'Avg Similarity',\n",
        "                          'Types Count', 'Tiers Range'],\n",
        "                'Value': [\n",
        "                    len(df),\n",
        "                    len(similar_pairs),\n",
        "                    np.mean([p['similarity'] for p in similar_pairs]) if similar_pairs else 0,\n",
        "                    df['reasoning_type'].nunique() if 'reasoning_type' in df.columns else 0,\n",
        "                    f\"{df['tier'].min()}-{df['tier'].max()}\" if 'tier' in df.columns else 'N/A'\n",
        "                ]\n",
        "            }\n",
        "            pd.DataFrame(overview_data).to_excel(writer, sheet_name='Overview', index=False)\n",
        "\n",
        "            # Sheet 2: Similar Pairs\n",
        "            if similar_pairs:\n",
        "                df_pairs = pd.DataFrame(similar_pairs)\n",
        "                df_pairs = df_pairs.sort_values('similarity', ascending=False)\n",
        "                df_pairs.to_excel(writer, sheet_name='Similar_Pairs', index=False)\n",
        "\n",
        "            # Sheet 3: Distribution\n",
        "            dist_data = []\n",
        "            for cat, cat_stats in stats.items():\n",
        "                for value, count in cat_stats['distribution'].items():\n",
        "                    dist_data.append({\n",
        "                        'Category': cat,\n",
        "                        'Value': value,\n",
        "                        'Count': count,\n",
        "                        'Percentage': count / len(df) * 100\n",
        "                    })\n",
        "            pd.DataFrame(dist_data).to_excel(writer, sheet_name='Distribution', index=False)\n",
        "\n",
        "            # Sheet 4: Fix Suggestions\n",
        "            fix_data = []\n",
        "            for sug in suggestions[:100]:  # Top 100\n",
        "                pair = sug['pair']\n",
        "                for fix in sug['fixes']:\n",
        "                    fix_data.append({\n",
        "                        'Prompt1_ID': pair['prompt1_id'],\n",
        "                        'Prompt2_ID': pair['prompt2_id'],\n",
        "                        'Similarity': pair['similarity'],\n",
        "                        'Fix_Method': fix['method'],\n",
        "                        'Priority': fix['priority'],\n",
        "                        'Description': fix['description']\n",
        "                    })\n",
        "            pd.DataFrame(fix_data).to_excel(writer, sheet_name='Fix_Suggestions', index=False)\n",
        "\n",
        "            # Sheet 5: Gaps Analysis\n",
        "            gaps = ReportGenerator.find_gaps(df)\n",
        "            pd.DataFrame(gaps).to_excel(writer, sheet_name='Gaps', index=False)\n",
        "\n",
        "        print(f\"‚úÖ Report saved to: {output_path}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def find_gaps(df):\n",
        "        \"\"\"Find coverage gaps\"\"\"\n",
        "        gaps = []\n",
        "\n",
        "        if 'reasoning_type' in df.columns and 'difficulty' in df.columns:\n",
        "            # Check all combinations\n",
        "            types = df['reasoning_type'].unique()\n",
        "            difficulties = ['easy', 'medium', 'hard']\n",
        "\n",
        "            for t in types:\n",
        "                for d in difficulties:\n",
        "                    count = len(df[(df['reasoning_type'] == t) &\n",
        "                                  (df['difficulty'] == d)])\n",
        "                    if count < 10:  # Threshold\n",
        "                        gaps.append({\n",
        "                            'Type': t,\n",
        "                            'Difficulty': d,\n",
        "                            'Current_Count': count,\n",
        "                            'Target': 10,\n",
        "                            'Gap': 10 - count\n",
        "                        })\n",
        "\n",
        "        return gaps"
      ],
      "metadata": {
        "id": "oP_2JCcOhR-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 7: Visualization\n",
        "# ‡∏ó‡∏≥‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó, tier, difficulty, domain ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢ similarity\n",
        "# ============================================\n",
        "def create_visualizations(df, similar_pairs, stats):\n",
        "    \"\"\"Create analysis visualizations\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "    # 1. Type distribution\n",
        "    if 'reasoning_type' in df.columns:\n",
        "        type_counts = df['reasoning_type'].value_counts().head(15)\n",
        "        type_counts.plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
        "        axes[0,0].set_title('Top 15 Reasoning Types')\n",
        "        axes[0,0].set_xlabel('Type')\n",
        "        axes[0,0].set_ylabel('Count')\n",
        "        axes[0,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # 2. Tier distribution\n",
        "    if 'tier' in df.columns:\n",
        "        tier_counts = df['tier'].value_counts().sort_index()\n",
        "        tier_counts.plot(kind='bar', ax=axes[0,1], color='lightgreen')\n",
        "        axes[0,1].set_title('Tier Distribution')\n",
        "        axes[0,1].set_xlabel('Tier')\n",
        "        axes[0,1].set_ylabel('Count')\n",
        "\n",
        "    # 3. Similarity distribution\n",
        "    if similar_pairs:\n",
        "        similarities = [p['similarity'] for p in similar_pairs]\n",
        "        axes[0,2].hist(similarities, bins=30, color='coral', edgecolor='black')\n",
        "        axes[0,2].set_title('Similarity Score Distribution')\n",
        "        axes[0,2].set_xlabel('Similarity')\n",
        "        axes[0,2].set_ylabel('Frequency')\n",
        "        axes[0,2].axvline(x=0.7, color='r', linestyle='--', label='Threshold')\n",
        "        axes[0,2].legend()\n",
        "\n",
        "    # 4. Difficulty distribution\n",
        "    if 'difficulty' in df.columns:\n",
        "        diff_counts = df['difficulty'].value_counts()\n",
        "        diff_counts.plot(kind='pie', ax=axes[1,0], autopct='%1.1f%%')\n",
        "        axes[1,0].set_title('Difficulty Distribution')\n",
        "\n",
        "    # 5. Domain distribution\n",
        "    if 'domain_context' in df.columns:\n",
        "        domain_counts = df['domain_context'].value_counts().head(10)\n",
        "        domain_counts.plot(kind='barh', ax=axes[1,1], color='plum')\n",
        "        axes[1,1].set_title('Top 10 Domains')\n",
        "        axes[1,1].set_xlabel('Count')\n",
        "\n",
        "    # 6. Redundancy by Type\n",
        "    if similar_pairs and 'reasoning_type' in df.columns:\n",
        "        from collections import defaultdict\n",
        "        redundancy_by_type = defaultdict(int)\n",
        "        for pair in similar_pairs:\n",
        "            redundancy_by_type[pair['type1']] += 1\n",
        "\n",
        "        top_redundant = dict(sorted(redundancy_by_type.items(),\n",
        "                                   key=lambda x: x[1], reverse=True)[:10])\n",
        "        axes[1,2].bar(range(len(top_redundant)), list(top_redundant.values()),\n",
        "                     color='salmon')\n",
        "        axes[1,2].set_xticks(range(len(top_redundant)))\n",
        "        axes[1,2].set_xticklabels(list(top_redundant.keys()), rotation=45, ha='right')\n",
        "        axes[1,2].set_title('Top 10 Types with Redundancy')\n",
        "        axes[1,2].set_ylabel('Redundant Pairs')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/redundancy_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "znEoPg0mhXlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 8: Main Pipeline\n",
        "# ‡∏£‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£: ‡πÇ‡∏´‡∏•‡∏î, ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå, ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥, ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞, ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô, ‡∏Å‡∏£‡∏≤‡∏ü, ‡∏™‡∏£‡∏∏‡∏õ\n",
        "# ============================================\n",
        "def main():\n",
        "    \"\"\"Main analysis pipeline\"\"\"\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"üîç REDUNDANCY CHECKER - 46 TYPE DATASET\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Create output directory\n",
        "    Path(Config.OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Load data\n",
        "    print(\"\\nüìä Loading data...\")\n",
        "    df = DataExtractor.load_all_files(Config.DATASET_DIR, Config.MAX_PROMPTS)\n",
        "    print(f\"‚úÖ Loaded {len(df)} prompts\")\n",
        "\n",
        "    # Basic info\n",
        "    print(\"\\nüìã Dataset Info:\")\n",
        "    print(f\"  Files: {df['file'].nunique()}\")\n",
        "    print(f\"  Types: {df['reasoning_type'].nunique() if 'reasoning_type' in df.columns else 'N/A'}\")\n",
        "    print(f\"  Tiers: {df['tier'].unique().tolist() if 'tier' in df.columns else 'N/A'}\")\n",
        "\n",
        "    # Analyze redundancy\n",
        "    print(\"\\nüîç Analyzing redundancy...\")\n",
        "    analyzer = RedundancyAnalyzer(df, Config)\n",
        "    similar_pairs = analyzer.analyze_all()\n",
        "    print(f\"‚úÖ Found {len(similar_pairs)} redundant pairs\")\n",
        "\n",
        "    # Get statistics\n",
        "    print(\"\\nüìà Calculating statistics...\")\n",
        "    stats = analyzer.get_distribution_stats()\n",
        "\n",
        "    # Generate suggestions\n",
        "    print(\"\\nüí° Generating fix suggestions...\")\n",
        "    fixer = RedundancyFixer()\n",
        "    suggestions = fixer.suggest_fixes(similar_pairs)\n",
        "\n",
        "    # Create report\n",
        "    print(\"\\nüìù Creating Excel report...\")\n",
        "    report_path = Path(Config.OUTPUT_DIR) / 'redundancy_report.xlsx'\n",
        "    ReportGenerator.create_excel_report(df, similar_pairs, stats, suggestions, report_path)\n",
        "\n",
        "    # Visualizations\n",
        "    print(\"\\nüìä Creating visualizations...\")\n",
        "    create_visualizations(df, similar_pairs, stats)\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ ANALYSIS COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nüìä Summary:\")\n",
        "    print(f\"  Total Prompts: {len(df)}\")\n",
        "    print(f\"  Redundant Pairs: {len(similar_pairs)}\")\n",
        "    print(f\"  Redundancy Rate: {len(similar_pairs) / (len(df)*(len(df)-1)/2) * 100:.2f}%\")\n",
        "\n",
        "    if stats.get('reasoning_type'):\n",
        "        print(f\"  Type Imbalance: {stats['reasoning_type']['imbalance_ratio']:.2f}x\")\n",
        "\n",
        "    print(f\"\\nüìÅ Files Generated:\")\n",
        "    print(f\"  - {report_path}\")\n",
        "    print(f\"  - /content/redundancy_analysis.png\")\n",
        "\n",
        "    return df, similar_pairs, stats"
      ],
      "metadata": {
        "id": "znPiIJWVhetj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 9: Run\n",
        "# ‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô Colab\n",
        "# ============================================\n",
        "if __name__ == \"__main__\":\n",
        "    df, pairs, stats = main()"
      ],
      "metadata": {
        "id": "LzvbGJ-nhqZt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}