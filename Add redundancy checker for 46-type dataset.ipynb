{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanatet8/Colab_Script/blob/main/Add%20redundancy%20checker%20for%2046-type%20dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# REDUNDANCY CHECKER FIXED VERSION\n",
        "# ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ tier ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô '13B' ‡πÅ‡∏•‡∏∞ error ‡∏≠‡∏∑‡πà‡∏ô‡πÜ\n",
        "# ============================================\n",
        "\n",
        "# ============================================\n",
        "# üìå Block 1: Setup & Mount\n",
        "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ + Mount Google Drive\n",
        "# ============================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install -q pandas numpy scikit-learn matplotlib seaborn openpyxl tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import re\n",
        "import json\n",
        "from collections import Counter, defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Libraries loaded\")"
      ],
      "metadata": {
        "id": "El9NnEM8WJZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 2: Configuration\n",
        "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å ‡πÄ‡∏ä‡πà‡∏ô path, batch size, threshold\n",
        "# ============================================\n",
        "class Config:\n",
        "    # Paths - ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô path dataset ‡πÅ‡∏•‡∏∞‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•\n",
        "    DATASET_DIR = '/content/drive/MyDrive/Dataset_Curation'\n",
        "    OUTPUT_DIR = '/content/drive/MyDrive/Dataset_Curation/redundancy_reports'\n",
        "\n",
        "    # Processing\n",
        "    BATCH_SIZE = 500  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô prompt ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ï‡πà‡∏≠ batch\n",
        "    MAX_PROMPTS = None  # None = ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏™‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î\n",
        "\n",
        "    # Redundancy Thresholds by Type & Tier\n",
        "    THRESHOLDS = {\n",
        "        # Type: [Tier1-2, Tier3-4, Tier5-6]\n",
        "        'causal_reasoning': [0.75, 0.60, 0.40],\n",
        "        'symbolic_reasoning': [0.70, 0.55, 0.35],\n",
        "        'meta_reasoning': [0.60, 0.45, 0.30],\n",
        "        'moral_ambiguity_tradeoff': [0.50, 0.35, 0.25],\n",
        "        'philosophical_logic': [0.45, 0.30, 0.20],\n",
        "        # Default ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö type ‡∏≠‡∏∑‡πà‡∏ô ‡πÜ\n",
        "        'default': [0.65, 0.50, 0.35]\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Config loaded\")"
      ],
      "metadata": {
        "id": "Ap0AljqXWPpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 3: Data Extraction\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå markdown, ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• metadata ‡πÅ‡∏•‡∏∞ prompt\n",
        "# ============================================\n",
        "class DataExtractor:\n",
        "    @staticmethod\n",
        "    def parse_block(block_text):\n",
        "        \"\"\"Extract data ‡∏à‡∏≤‡∏Å 1 block ‡∏Ç‡∏≠‡∏á prompt\"\"\"\n",
        "        data = {}\n",
        "\n",
        "        # Metadata section\n",
        "        meta_match = re.search(r'###\\s*Metadata\\s*\\n(.*?)(?=\\n###|\\n##|$)',\n",
        "                              block_text, re.DOTALL)\n",
        "        if meta_match:\n",
        "            for line in meta_match.group(1).split('\\n'):\n",
        "                if ':' in line:\n",
        "                    key, value = line.split(':', 1)\n",
        "                    data[key.strip()] = value.strip()\n",
        "\n",
        "        # Prompts (TH, EN, ZH)\n",
        "        for lang in ['TH', 'EN', 'ZH']:\n",
        "            pattern = rf'###?\\s*Prompt\\s*\\({lang}\\)\\s*\\n(.*?)(?=\\n###|\\n##|$)'\n",
        "            match = re.search(pattern, block_text, re.DOTALL)\n",
        "            if match:\n",
        "                data[f'prompt_{lang.lower()}'] = match.group(1).strip()\n",
        "\n",
        "        # Reasoning\n",
        "        reason_match = re.search(r'###\\s*Reasoning\\s*\\n(.*?)(?=\\n###|$)',\n",
        "                                block_text, re.DOTALL)\n",
        "        if reason_match:\n",
        "            data['reasoning'] = reason_match.group(1).strip()\n",
        "\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def load_all_files(dataset_dir, max_prompts=None):\n",
        "        \"\"\"‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå MD ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\"\"\"\n",
        "        all_prompts = []\n",
        "        md_files = sorted(Path(dataset_dir).glob('*_batch_*.md'))\n",
        "\n",
        "        print(f\"üìÇ ‡∏û‡∏ö {len(md_files)} batch files\")\n",
        "\n",
        "        for file_path in tqdm(md_files, desc=\"Loading files\"):\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # ‡πÅ‡∏ö‡πà‡∏á‡πÇ‡∏î‡∏¢ ## Prompt N\n",
        "            blocks = re.split(r'##\\s*Prompt\\s+\\d+', content)[1:]\n",
        "\n",
        "            for i, block in enumerate(blocks):\n",
        "                if max_prompts and len(all_prompts) >= max_prompts:\n",
        "                    break\n",
        "\n",
        "                prompt_data = DataExtractor.parse_block(block)\n",
        "                prompt_data['file'] = file_path.name\n",
        "                prompt_data['prompt_id'] = f\"{file_path.stem}_p{i+1:03d}\"\n",
        "\n",
        "                # Clean tier value (handle '13B' case)\n",
        "                if 'tier' in prompt_data:\n",
        "                    tier_val = prompt_data['tier']\n",
        "                    # ‡∏ñ‡πâ‡∏≤ tier ‡πÄ‡∏õ‡πá‡∏ô '13B' ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ 'B' ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ default tier\n",
        "                    if 'B' in str(tier_val).upper():\n",
        "                        prompt_data['model_size'] = tier_val\n",
        "                        prompt_data['tier'] = '2'  # Default tier\n",
        "                    elif not str(tier_val).isdigit():\n",
        "                        prompt_data['tier'] = '2'  # Default if not numeric\n",
        "                    else:\n",
        "                        # Convert to int to validate\n",
        "                        try:\n",
        "                            tier_int = int(tier_val)\n",
        "                            if tier_int > 6:\n",
        "                                prompt_data['model_size'] = f\"{tier_int}B\"\n",
        "                                prompt_data['tier'] = '2'\n",
        "                            else:\n",
        "                                prompt_data['tier'] = str(tier_int)\n",
        "                        except:\n",
        "                            prompt_data['tier'] = '2'\n",
        "\n",
        "                all_prompts.append(prompt_data)\n",
        "\n",
        "            if max_prompts and len(all_prompts) >= max_prompts:\n",
        "                break\n",
        "\n",
        "        return pd.DataFrame(all_prompts)\n",
        "\n",
        "print(\"‚úÖ Data Extractor ready\")"
      ],
      "metadata": {
        "id": "NHb6UEBVWTYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 4: Redundancy Analysis - FIXED\n",
        "# ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á prompt ‡∏î‡πâ‡∏ß‡∏¢ TF-IDF + cosine similarity\n",
        "# ============================================\n",
        "class RedundancyAnalyzer:\n",
        "    def __init__(self, df, config):\n",
        "        self.df = df\n",
        "        self.config = config\n",
        "        self.similarity_matrices = {}\n",
        "\n",
        "        # Clean tier column\n",
        "        if 'tier' in self.df.columns:\n",
        "            self.df['tier'] = self.df['tier'].apply(self.clean_tier_value)\n",
        "\n",
        "    def clean_tier_value(self, tier_val):\n",
        "        \"\"\"Clean tier value to ensure it's numeric 1-6\"\"\"\n",
        "        if pd.isna(tier_val):\n",
        "            return 2\n",
        "\n",
        "        tier_str = str(tier_val)\n",
        "\n",
        "        # Handle '13B' or similar cases\n",
        "        if 'B' in tier_str.upper():\n",
        "            return 2  # Default tier for model sizes\n",
        "\n",
        "        # Try to extract numeric value\n",
        "        try:\n",
        "            tier_num = int(re.search(r'\\d+', tier_str).group())\n",
        "            if 1 <= tier_num <= 6:\n",
        "                return tier_num\n",
        "            else:\n",
        "                return 2  # Default if out of range\n",
        "        except:\n",
        "            return 2  # Default if can't parse\n",
        "\n",
        "    def get_threshold(self, reasoning_type, tier):\n",
        "        \"\"\"‡∏î‡∏∂‡∏á threshold ‡∏ï‡∏≤‡∏° reasoning_type ‡πÅ‡∏•‡∏∞ tier\"\"\"\n",
        "        # Ensure tier is int\n",
        "        try:\n",
        "            tier = int(tier)\n",
        "        except:\n",
        "            tier = 2\n",
        "\n",
        "        tier_idx = min((tier-1)//2, 2)\n",
        "\n",
        "        if reasoning_type in self.config.THRESHOLDS:\n",
        "            thresholds = self.config.THRESHOLDS[reasoning_type]\n",
        "        else:\n",
        "            thresholds = self.config.THRESHOLDS['default']\n",
        "        return thresholds[tier_idx]\n",
        "\n",
        "    def calculate_similarity_batch(self, df_batch, text_col='prompt_en'):\n",
        "        \"\"\"‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì similarity ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö batch\"\"\"\n",
        "        # Use prompt_th as fallback if prompt_en doesn't exist\n",
        "        if text_col not in df_batch.columns or df_batch[text_col].isna().all():\n",
        "            text_col = 'prompt_th'\n",
        "\n",
        "        valid_df = df_batch[df_batch[text_col].notna()].reset_index(drop=True)\n",
        "        if len(valid_df) < 2:\n",
        "            return None, []\n",
        "\n",
        "        # TF-IDF\n",
        "        try:\n",
        "            vectorizer = TfidfVectorizer(\n",
        "                max_features=500,\n",
        "                ngram_range=(1, 3),\n",
        "                min_df=1,  # Changed from 2 to 1 for small datasets\n",
        "                max_df=0.95\n",
        "            )\n",
        "            tfidf_matrix = vectorizer.fit_transform(valid_df[text_col])\n",
        "            sim_matrix = cosine_similarity(tfidf_matrix)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error in TF-IDF: {e}\")\n",
        "            return None, []\n",
        "\n",
        "        # ‡∏´‡∏≤ pair ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏ô threshold\n",
        "        pairs = []\n",
        "        for i in range(len(sim_matrix)):\n",
        "            for j in range(i+1, len(sim_matrix)):\n",
        "                row_i = valid_df.iloc[i]\n",
        "                row_j = valid_df.iloc[j]\n",
        "\n",
        "                tier_i = int(row_i.get('tier', 2))\n",
        "                tier_j = int(row_j.get('tier', 2))\n",
        "                type_i = row_i.get('reasoning_type', 'default')\n",
        "\n",
        "                threshold = self.get_threshold(type_i, max(tier_i, tier_j))\n",
        "\n",
        "                if sim_matrix[i][j] >= threshold:\n",
        "                    pairs.append({\n",
        "                        'idx1': i,\n",
        "                        'idx2': j,\n",
        "                        'prompt1_id': row_i['prompt_id'],\n",
        "                        'prompt2_id': row_j['prompt_id'],\n",
        "                        'similarity': sim_matrix[i][j],\n",
        "                        'threshold_used': threshold,\n",
        "                        'type1': type_i,\n",
        "                        'type2': row_j.get('reasoning_type', 'default'),\n",
        "                        'tier1': tier_i,\n",
        "                        'tier2': tier_j,\n",
        "                        'prompt1': row_i[text_col][:100] if text_col in row_i.index else 'N/A',\n",
        "                        'prompt2': row_j[text_col][:100] if text_col in row_j.index else 'N/A'\n",
        "                    })\n",
        "        return sim_matrix, pairs\n",
        "\n",
        "    def analyze_all(self):\n",
        "        \"\"\"‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏∏‡∏Å prompt ‡πÉ‡∏ô batch\"\"\"\n",
        "        all_pairs = []\n",
        "        batch_size = self.config.BATCH_SIZE\n",
        "        n_batches = (len(self.df) + batch_size - 1) // batch_size\n",
        "\n",
        "        for batch_idx in tqdm(range(n_batches), desc=\"Analyzing batches\"):\n",
        "            start = batch_idx * batch_size\n",
        "            end = min(start + batch_size, len(self.df))\n",
        "            df_batch = self.df.iloc[start:end]\n",
        "            _, pairs = self.calculate_similarity_batch(df_batch)\n",
        "            all_pairs.extend(pairs)\n",
        "\n",
        "        return all_pairs\n",
        "\n",
        "    def get_distribution_stats(self):\n",
        "        \"\"\"‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\"\"\"\n",
        "        stats = {}\n",
        "        categories = ['reasoning_type', 'sub_type', 'domain_context', 'difficulty', 'tier']\n",
        "\n",
        "        for cat in categories:\n",
        "            if cat in self.df.columns:\n",
        "                value_counts = self.df[cat].value_counts()\n",
        "                stats[cat] = {\n",
        "                    'distribution': value_counts.to_dict(),\n",
        "                    'unique': len(value_counts),\n",
        "                    'max': value_counts.max(),\n",
        "                    'min': value_counts.min(),\n",
        "                    'std': value_counts.std(),\n",
        "                    'imbalance_ratio': value_counts.max() / value_counts.min() if value_counts.min() > 0 else float('inf')\n",
        "                }\n",
        "        return stats\n",
        "\n",
        "print(\"‚úÖ Redundancy Analyzer ready\")"
      ],
      "metadata": {
        "id": "0BzPoBtXWYOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 5: Fix Suggestions\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏π‡πà prompt ‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥\n",
        "# ============================================\n",
        "class RedundancyFixer:\n",
        "    @staticmethod\n",
        "    def suggest_fixes(similar_pairs):\n",
        "        \"\"\"Suggest fixes for redundant pairs\"\"\"\n",
        "        suggestions = []\n",
        "\n",
        "        for pair in similar_pairs:\n",
        "            fix_options = []\n",
        "\n",
        "            # Domain shift suggestion\n",
        "            if pair['similarity'] > 0.9:\n",
        "                fix_options.append({\n",
        "                    'method': 'domain_shift',\n",
        "                    'priority': 'high',\n",
        "                    'description': 'Change domain context completely'\n",
        "                })\n",
        "\n",
        "            # Complexity change\n",
        "            if pair['tier1'] == pair['tier2']:\n",
        "                fix_options.append({\n",
        "                    'method': 'complexity_change',\n",
        "                    'priority': 'medium',\n",
        "                    'description': f'Adjust complexity (current tier: {pair[\"tier1\"]})'\n",
        "                })\n",
        "\n",
        "            # Angle change\n",
        "            if 0.7 < pair['similarity'] <= 0.9:\n",
        "                fix_options.append({\n",
        "                    'method': 'angle_change',\n",
        "                    'priority': 'medium',\n",
        "                    'description': 'Change questioning angle or framing'\n",
        "                })\n",
        "\n",
        "            suggestions.append({\n",
        "                'pair': pair,\n",
        "                'fixes': fix_options\n",
        "            })\n",
        "\n",
        "        return suggestions\n",
        "\n",
        "print(\"‚úÖ Fixer ready\")"
      ],
      "metadata": {
        "id": "HkteEe2BWa9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 6: Report Generation\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô Excel ‡∏Ñ‡∏£‡∏ö‡∏ä‡∏∏‡∏î + ‡∏´‡∏≤ coverage gaps\n",
        "# ============================================\n",
        "class ReportGenerator:\n",
        "    @staticmethod\n",
        "    def create_excel_report(df, similar_pairs, stats, suggestions, output_path):\n",
        "        \"\"\"Generate comprehensive Excel report\"\"\"\n",
        "\n",
        "        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
        "            # Sheet 1: Overview\n",
        "            overview_data = {\n",
        "                'Metric': ['Total Prompts', 'Redundant Pairs', 'Avg Similarity',\n",
        "                          'Types Count', 'Tiers Range'],\n",
        "                'Value': [\n",
        "                    len(df),\n",
        "                    len(similar_pairs),\n",
        "                    np.mean([p['similarity'] for p in similar_pairs]) if similar_pairs else 0,\n",
        "                    df['reasoning_type'].nunique() if 'reasoning_type' in df.columns else 0,\n",
        "                    f\"{df['tier'].min()}-{df['tier'].max()}\" if 'tier' in df.columns else 'N/A'\n",
        "                ]\n",
        "            }\n",
        "            pd.DataFrame(overview_data).to_excel(writer, sheet_name='Overview', index=False)\n",
        "\n",
        "            # Sheet 2: Similar Pairs\n",
        "            if similar_pairs:\n",
        "                df_pairs = pd.DataFrame(similar_pairs)\n",
        "                df_pairs = df_pairs.sort_values('similarity', ascending=False)\n",
        "                df_pairs.to_excel(writer, sheet_name='Similar_Pairs', index=False)\n",
        "\n",
        "            # Sheet 3: Distribution\n",
        "            dist_data = []\n",
        "            for cat, cat_stats in stats.items():\n",
        "                for value, count in cat_stats['distribution'].items():\n",
        "                    dist_data.append({\n",
        "                        'Category': cat,\n",
        "                        'Value': value,\n",
        "                        'Count': count,\n",
        "                        'Percentage': count / len(df) * 100\n",
        "                    })\n",
        "            pd.DataFrame(dist_data).to_excel(writer, sheet_name='Distribution', index=False)\n",
        "\n",
        "            # Sheet 4: Fix Suggestions\n",
        "            fix_data = []\n",
        "            for sug in suggestions[:100]:  # Top 100\n",
        "                pair = sug['pair']\n",
        "                for fix in sug['fixes']:\n",
        "                    fix_data.append({\n",
        "                        'Prompt1_ID': pair['prompt1_id'],\n",
        "                        'Prompt2_ID': pair['prompt2_id'],\n",
        "                        'Similarity': pair['similarity'],\n",
        "                        'Fix_Method': fix['method'],\n",
        "                        'Priority': fix['priority'],\n",
        "                        'Description': fix['description']\n",
        "                    })\n",
        "            if fix_data:\n",
        "                pd.DataFrame(fix_data).to_excel(writer, sheet_name='Fix_Suggestions', index=False)\n",
        "\n",
        "            # Sheet 5: Gaps Analysis\n",
        "            gaps = ReportGenerator.find_gaps(df)\n",
        "            if gaps:\n",
        "                pd.DataFrame(gaps).to_excel(writer, sheet_name='Gaps', index=False)\n",
        "\n",
        "        print(f\"‚úÖ Report saved to: {output_path}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def find_gaps(df):\n",
        "        \"\"\"Find coverage gaps\"\"\"\n",
        "        gaps = []\n",
        "\n",
        "        if 'reasoning_type' in df.columns and 'difficulty' in df.columns:\n",
        "            # Check all combinations\n",
        "            types = df['reasoning_type'].unique()\n",
        "            difficulties = ['easy', 'medium', 'hard']\n",
        "\n",
        "            for t in types:\n",
        "                for d in difficulties:\n",
        "                    count = len(df[(df['reasoning_type'] == t) &\n",
        "                                  (df['difficulty'] == d)])\n",
        "                    if count < 10:  # Threshold\n",
        "                        gaps.append({\n",
        "                            'Type': t,\n",
        "                            'Difficulty': d,\n",
        "                            'Current_Count': count,\n",
        "                            'Target': 10,\n",
        "                            'Gap': 10 - count\n",
        "                        })\n",
        "\n",
        "        return gaps\n",
        "\n",
        "print(\"‚úÖ Report Generator ready\")"
      ],
      "metadata": {
        "id": "y1EScp2LWep7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 7: Visualization\n",
        "# ‡∏ó‡∏≥‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó, tier, difficulty, domain ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢ similarity\n",
        "# ============================================\n",
        "def create_visualizations(df, similar_pairs, stats):\n",
        "    \"\"\"Create analysis visualizations\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "    # 1. Type distribution\n",
        "    if 'reasoning_type' in df.columns:\n",
        "        type_counts = df['reasoning_type'].value_counts().head(15)\n",
        "        type_counts.plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
        "        axes[0,0].set_title('Top 15 Reasoning Types')\n",
        "        axes[0,0].set_xlabel('Type')\n",
        "        axes[0,0].set_ylabel('Count')\n",
        "        axes[0,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # 2. Tier distribution\n",
        "    if 'tier' in df.columns:\n",
        "        # Ensure tier values are clean\n",
        "        tier_counts = df['tier'].value_counts().sort_index()\n",
        "        tier_counts.plot(kind='bar', ax=axes[0,1], color='lightgreen')\n",
        "        axes[0,1].set_title('Tier Distribution')\n",
        "        axes[0,1].set_xlabel('Tier')\n",
        "        axes[0,1].set_ylabel('Count')\n",
        "\n",
        "    # 3. Similarity distribution\n",
        "    if similar_pairs:\n",
        "        similarities = [p['similarity'] for p in similar_pairs]\n",
        "        axes[0,2].hist(similarities, bins=30, color='coral', edgecolor='black')\n",
        "        axes[0,2].set_title('Similarity Score Distribution')\n",
        "        axes[0,2].set_xlabel('Similarity')\n",
        "        axes[0,2].set_ylabel('Frequency')\n",
        "        axes[0,2].axvline(x=0.7, color='r', linestyle='--', label='Threshold')\n",
        "        axes[0,2].legend()\n",
        "\n",
        "    # 4. Difficulty distribution\n",
        "    if 'difficulty' in df.columns:\n",
        "        diff_counts = df['difficulty'].value_counts()\n",
        "        diff_counts.plot(kind='pie', ax=axes[1,0], autopct='%1.1f%%')\n",
        "        axes[1,0].set_title('Difficulty Distribution')\n",
        "\n",
        "    # 5. Domain distribution\n",
        "    if 'domain_context' in df.columns:\n",
        "        domain_counts = df['domain_context'].value_counts().head(10)\n",
        "        domain_counts.plot(kind='barh', ax=axes[1,1], color='plum')\n",
        "        axes[1,1].set_title('Top 10 Domains')\n",
        "        axes[1,1].set_xlabel('Count')\n",
        "\n",
        "    # 6. Redundancy by Type\n",
        "    if similar_pairs and 'reasoning_type' in df.columns:\n",
        "        redundancy_by_type = defaultdict(int)\n",
        "        for pair in similar_pairs:\n",
        "            redundancy_by_type[pair['type1']] += 1\n",
        "\n",
        "        if redundancy_by_type:\n",
        "            top_redundant = dict(sorted(redundancy_by_type.items(),\n",
        "                                       key=lambda x: x[1], reverse=True)[:10])\n",
        "            axes[1,2].bar(range(len(top_redundant)), list(top_redundant.values()),\n",
        "                         color='salmon')\n",
        "            axes[1,2].set_xticks(range(len(top_redundant)))\n",
        "            axes[1,2].set_xticklabels(list(top_redundant.keys()), rotation=45, ha='right')\n",
        "            axes[1,2].set_title('Top 10 Types with Redundancy')\n",
        "            axes[1,2].set_ylabel('Redundant Pairs')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save figure\n",
        "    output_path = '/content/redundancy_analysis.png'\n",
        "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"üìä Visualization saved to: {output_path}\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"‚úÖ Visualization ready\")"
      ],
      "metadata": {
        "id": "7M750KYdWhp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 8: Main Pipeline\n",
        "# ‡∏£‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£: ‡πÇ‡∏´‡∏•‡∏î, ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå, ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥, ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞, ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô, ‡∏Å‡∏£‡∏≤‡∏ü, ‡∏™‡∏£‡∏∏‡∏õ\n",
        "# ============================================\n",
        "def main():\n",
        "    \"\"\"Main analysis pipeline\"\"\"\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"üîç REDUNDANCY CHECKER - 46 TYPE DATASET\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Create output directory\n",
        "    Path(Config.OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Load data\n",
        "    print(\"\\nüìä Loading data...\")\n",
        "    df = DataExtractor.load_all_files(Config.DATASET_DIR, Config.MAX_PROMPTS)\n",
        "    print(f\"‚úÖ Loaded {len(df)} prompts\")\n",
        "\n",
        "    # Basic info\n",
        "    print(\"\\nüìã Dataset Info:\")\n",
        "    print(f\"  Files: {df['file'].nunique()}\")\n",
        "    print(f\"  Types: {df['reasoning_type'].nunique() if 'reasoning_type' in df.columns else 'N/A'}\")\n",
        "\n",
        "    if 'tier' in df.columns:\n",
        "        unique_tiers = df['tier'].unique().tolist()\n",
        "        print(f\"  Tiers: {sorted([t for t in unique_tiers if str(t).isdigit()])}\")\n",
        "\n",
        "    # Check for model_size column\n",
        "    if 'model_size' in df.columns:\n",
        "        print(f\"  Model sizes: {df['model_size'].dropna().unique().tolist()}\")\n",
        "\n",
        "    # Analyze redundancy\n",
        "    print(\"\\nüîç Analyzing redundancy...\")\n",
        "    analyzer = RedundancyAnalyzer(df, Config)\n",
        "    similar_pairs = analyzer.analyze_all()\n",
        "    print(f\"‚úÖ Found {len(similar_pairs)} redundant pairs\")\n",
        "\n",
        "    # Get statistics\n",
        "    print(\"\\nüìà Calculating statistics...\")\n",
        "    stats = analyzer.get_distribution_stats()\n",
        "\n",
        "    # Generate suggestions\n",
        "    print(\"\\nüí° Generating fix suggestions...\")\n",
        "    fixer = RedundancyFixer()\n",
        "    suggestions = fixer.suggest_fixes(similar_pairs)\n",
        "\n",
        "    # Create report\n",
        "    print(\"\\nüìù Creating Excel report...\")\n",
        "    report_path = Path(Config.OUTPUT_DIR) / 'redundancy_report.xlsx'\n",
        "    ReportGenerator.create_excel_report(df, similar_pairs, stats, suggestions, report_path)\n",
        "\n",
        "    # Visualizations\n",
        "    print(\"\\nüìä Creating visualizations...\")\n",
        "    create_visualizations(df, similar_pairs, stats)\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ ANALYSIS COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nüìä Summary:\")\n",
        "    print(f\"  Total Prompts: {len(df)}\")\n",
        "    print(f\"  Redundant Pairs: {len(similar_pairs)}\")\n",
        "\n",
        "    if len(df) > 1:\n",
        "        max_pairs = len(df) * (len(df) - 1) / 2\n",
        "        redundancy_rate = len(similar_pairs) / max_pairs * 100\n",
        "        print(f\"  Redundancy Rate: {redundancy_rate:.2f}%\")\n",
        "\n",
        "    if stats.get('reasoning_type'):\n",
        "        print(f\"  Type Imbalance: {stats['reasoning_type']['imbalance_ratio']:.2f}x\")\n",
        "\n",
        "    print(f\"\\nüìÅ Files Generated:\")\n",
        "    print(f\"  - {report_path}\")\n",
        "    print(f\"  - /content/redundancy_analysis.png\")\n",
        "\n",
        "    return df, similar_pairs, stats\n",
        "\n",
        "print(\"‚úÖ All functions ready\")"
      ],
      "metadata": {
        "id": "pSAH50qLWk58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üìå Block 9: Run\n",
        "# ‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô Colab\n",
        "# ============================================\n",
        "if __name__ == \"__main__\":\n",
        "    df, pairs, stats = main()\n",
        "    print(\"\\nüéâ Done! Check the output files in your Drive.\")"
      ],
      "metadata": {
        "id": "3mzlfXWdWpLG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}